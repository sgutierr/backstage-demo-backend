'use strict';

var catalogModel = require('@backstage/catalog-model');
var errors = require('@backstage/errors');
var integration = require('@backstage/integration');
var pluginScaffolderCommon = require('@backstage/plugin-scaffolder-common');
var alpha = require('@backstage/plugin-scaffolder-common/alpha');
var express = require('express');
var Router = require('express-promise-router');
var jsonschema = require('jsonschema');
var zod = require('zod');
var pluginScaffolderNode = require('@backstage/plugin-scaffolder-node');
var yaml = require('yaml');
var fs = require('fs-extra');
var backendCommon = require('@backstage/backend-common');
var path = require('path');
var luxon = require('luxon');
var globby = require('globby');
var isbinaryfile = require('isbinaryfile');
var vm2 = require('vm2');
var get = require('lodash/get');
var octokit = require('octokit');
var child_process = require('child_process');
var stream = require('stream');
var webhooks = require('@octokit/webhooks');
var azureDevopsNodeApi = require('azure-devops-node-api');
var fetch = require('node-fetch');
var crypto = require('crypto');
var octokitPluginCreatePullRequest = require('octokit-plugin-create-pull-request');
var fs$1 = require('fs');
var limiterFactory = require('p-limit');
var node = require('@gitbeaker/node');
var uuid = require('uuid');
var ObservableImpl = require('zen-observable');
var PQueue = require('p-queue');
var winston = require('winston');
var nunjucks = require('nunjucks');
var lodash = require('lodash');
var pluginPermissionNode = require('@backstage/plugin-permission-node');
var promClient = require('prom-client');
var pluginPermissionCommon = require('@backstage/plugin-permission-common');
var url = require('url');
var os = require('os');
var pluginCatalogNode = require('@backstage/plugin-catalog-node');

function _interopDefaultLegacy (e) { return e && typeof e === 'object' && 'default' in e ? e : { 'default': e }; }

function _interopNamespace(e) {
  if (e && e.__esModule) return e;
  var n = Object.create(null);
  if (e) {
    Object.keys(e).forEach(function (k) {
      if (k !== 'default') {
        var d = Object.getOwnPropertyDescriptor(e, k);
        Object.defineProperty(n, k, d.get ? d : {
          enumerable: true,
          get: function () { return e[k]; }
        });
      }
    });
  }
  n["default"] = e;
  return Object.freeze(n);
}

var express__default = /*#__PURE__*/_interopDefaultLegacy(express);
var Router__default = /*#__PURE__*/_interopDefaultLegacy(Router);
var yaml__default = /*#__PURE__*/_interopDefaultLegacy(yaml);
var yaml__namespace = /*#__PURE__*/_interopNamespace(yaml);
var fs__default = /*#__PURE__*/_interopDefaultLegacy(fs);
var path__default = /*#__PURE__*/_interopDefaultLegacy(path);
var globby__default = /*#__PURE__*/_interopDefaultLegacy(globby);
var get__default = /*#__PURE__*/_interopDefaultLegacy(get);
var fetch__default = /*#__PURE__*/_interopDefaultLegacy(fetch);
var crypto__default = /*#__PURE__*/_interopDefaultLegacy(crypto);
var limiterFactory__default = /*#__PURE__*/_interopDefaultLegacy(limiterFactory);
var ObservableImpl__default = /*#__PURE__*/_interopDefaultLegacy(ObservableImpl);
var PQueue__default = /*#__PURE__*/_interopDefaultLegacy(PQueue);
var winston__namespace = /*#__PURE__*/_interopNamespace(winston);
var nunjucks__default = /*#__PURE__*/_interopDefaultLegacy(nunjucks);
var os__default = /*#__PURE__*/_interopDefaultLegacy(os);

const id$4 = "catalog:register";
const examples$4 = [
  {
    description: "Register with the catalog",
    example: yaml__default["default"].stringify({
      steps: [
        {
          action: id$4,
          id: "register-with-catalog",
          name: "Register with the catalog",
          input: {
            catalogInfoUrl: "http://github.com/backstage/backstage/blob/master/catalog-info.yaml"
          }
        }
      ]
    })
  }
];
function createCatalogRegisterAction(options) {
  const { catalogClient, integrations } = options;
  return pluginScaffolderNode.createTemplateAction({
    id: id$4,
    description: "Registers entities from a catalog descriptor file in the workspace into the software catalog.",
    examples: examples$4,
    schema: {
      input: {
        oneOf: [
          {
            type: "object",
            required: ["catalogInfoUrl"],
            properties: {
              catalogInfoUrl: {
                title: "Catalog Info URL",
                description: "An absolute URL pointing to the catalog info file location",
                type: "string"
              },
              optional: {
                title: "Optional",
                description: "Permit the registered location to optionally exist. Default: false",
                type: "boolean"
              }
            }
          },
          {
            type: "object",
            required: ["repoContentsUrl"],
            properties: {
              repoContentsUrl: {
                title: "Repository Contents URL",
                description: "An absolute URL pointing to the root of a repository directory tree",
                type: "string"
              },
              catalogInfoPath: {
                title: "Fetch URL",
                description: "A relative path from the repo root pointing to the catalog info file, defaults to /catalog-info.yaml",
                type: "string"
              },
              optional: {
                title: "Optional",
                description: "Permit the registered location to optionally exist. Default: false",
                type: "boolean"
              }
            }
          }
        ]
      },
      output: {
        type: "object",
        required: ["catalogInfoUrl"],
        properties: {
          entityRef: {
            type: "string"
          },
          catalogInfoUrl: {
            type: "string"
          }
        }
      }
    },
    async handler(ctx) {
      var _a, _b;
      const { input } = ctx;
      let catalogInfoUrl;
      if ("catalogInfoUrl" in input) {
        catalogInfoUrl = input.catalogInfoUrl;
      } else {
        const { repoContentsUrl, catalogInfoPath = "/catalog-info.yaml" } = input;
        const integration = integrations.byUrl(repoContentsUrl);
        if (!integration) {
          throw new errors.InputError(
            `No integration found for host ${repoContentsUrl}`
          );
        }
        catalogInfoUrl = integration.resolveUrl({
          base: repoContentsUrl,
          url: catalogInfoPath
        });
      }
      ctx.logger.info(`Registering ${catalogInfoUrl} in the catalog`);
      await catalogClient.addLocation(
        {
          type: "url",
          target: catalogInfoUrl
        },
        ((_a = ctx.secrets) == null ? void 0 : _a.backstageToken) ? { token: ctx.secrets.backstageToken } : {}
      );
      try {
        const result = await catalogClient.addLocation(
          {
            dryRun: true,
            type: "url",
            target: catalogInfoUrl
          },
          ((_b = ctx.secrets) == null ? void 0 : _b.backstageToken) ? { token: ctx.secrets.backstageToken } : {}
        );
        if (result.entities.length > 0) {
          const { entities } = result;
          let entity;
          entity = entities.find(
            (e) => !e.metadata.name.startsWith("generated-") && e.kind === "Component"
          );
          if (!entity) {
            entity = entities.find(
              (e) => !e.metadata.name.startsWith("generated-")
            );
          }
          if (!entity) {
            entity = entities[0];
          }
          ctx.output("entityRef", catalogModel.stringifyEntityRef(entity));
        }
      } catch (e) {
        if (!input.optional) {
          throw e;
        }
      }
      ctx.output("catalogInfoUrl", catalogInfoUrl);
    }
  });
}

const id$3 = "catalog:write";
const examples$3 = [
  {
    description: "Write a catalog yaml file",
    example: yaml__namespace.stringify({
      steps: [
        {
          action: id$3,
          id: "create-catalog-info-file",
          name: "Create catalog file",
          input: {
            entity: {
              apiVersion: "backstage.io/v1alpha1",
              kind: "Component",
              metadata: {
                name: "test",
                annotations: {}
              },
              spec: {
                type: "service",
                lifecycle: "production",
                owner: "default/owner"
              }
            }
          }
        }
      ]
    })
  }
];
function createCatalogWriteAction() {
  return pluginScaffolderNode.createTemplateAction({
    id: id$3,
    description: "Writes the catalog-info.yaml for your template",
    schema: {
      input: zod.z.object({
        filePath: zod.z.string().optional().describe("Defaults to catalog-info.yaml"),
        // TODO: this should reference an zod entity validator if it existed.
        entity: zod.z.record(zod.z.any()).describe(
          "You can provide the same values used in the Entity schema."
        )
      })
    },
    examples: examples$3,
    supportsDryRun: true,
    async handler(ctx) {
      ctx.logStream.write(`Writing catalog-info.yaml`);
      const { filePath, entity } = ctx.input;
      const path = filePath != null ? filePath : "catalog-info.yaml";
      await fs__default["default"].writeFile(
        backendCommon.resolveSafeChildPath(ctx.workspacePath, path),
        yaml__namespace.stringify(entity)
      );
    }
  });
}

const id$2 = "catalog:fetch";
const examples$2 = [
  {
    description: "Fetch entity by reference",
    example: yaml__default["default"].stringify({
      steps: [
        {
          action: id$2,
          id: "fetch",
          name: "Fetch catalog entity",
          input: {
            entityRef: "component:default/name"
          }
        }
      ]
    })
  },
  {
    description: "Fetch multiple entities by referencse",
    example: yaml__default["default"].stringify({
      steps: [
        {
          action: id$2,
          id: "fetchMultiple",
          name: "Fetch catalog entities",
          input: {
            entityRefs: ["component:default/name"]
          }
        }
      ]
    })
  }
];
function createFetchCatalogEntityAction(options) {
  const { catalogClient } = options;
  return pluginScaffolderNode.createTemplateAction({
    id: id$2,
    description: "Returns entity or entities from the catalog by entity reference(s)",
    examples: examples$2,
    supportsDryRun: true,
    schema: {
      input: zod.z.object({
        entityRef: zod.z.string({
          description: "Entity reference of the entity to get"
        }).optional(),
        entityRefs: zod.z.array(zod.z.string(), {
          description: "Entity references of the entities to get"
        }).optional(),
        optional: zod.z.boolean({
          description: "Allow the entity or entities to optionally exist. Default: false"
        }).optional(),
        defaultKind: zod.z.string({ description: "The default kind" }).optional(),
        defaultNamespace: zod.z.string({ description: "The default namespace" }).optional()
      }),
      output: zod.z.object({
        entity: zod.z.any({
          description: "Object containing same values used in the Entity schema. Only when used with `entityRef` parameter."
        }).optional(),
        entities: zod.z.array(
          zod.z.any({
            description: "Array containing objects with same values used in the Entity schema. Only when used with `entityRefs` parameter."
          })
        ).optional()
      })
    },
    async handler(ctx) {
      var _a, _b;
      const { entityRef, entityRefs, optional, defaultKind, defaultNamespace } = ctx.input;
      if (!entityRef && !entityRefs) {
        if (optional) {
          return;
        }
        throw new Error("Missing entity reference or references");
      }
      if (entityRef) {
        const entity = await catalogClient.getEntityByRef(
          catalogModel.stringifyEntityRef(
            catalogModel.parseEntityRef(entityRef, { defaultKind, defaultNamespace })
          ),
          {
            token: (_a = ctx.secrets) == null ? void 0 : _a.backstageToken
          }
        );
        if (!entity && !optional) {
          throw new Error(`Entity ${entityRef} not found`);
        }
        ctx.output("entity", entity != null ? entity : null);
      }
      if (entityRefs) {
        const entities = await catalogClient.getEntitiesByRefs(
          {
            entityRefs: entityRefs.map(
              (ref) => catalogModel.stringifyEntityRef(
                catalogModel.parseEntityRef(ref, { defaultKind, defaultNamespace })
              )
            )
          },
          {
            token: (_b = ctx.secrets) == null ? void 0 : _b.backstageToken
          }
        );
        const finalEntities = entities.items.map((e, i) => {
          if (!e && !optional) {
            throw new Error(`Entity ${entityRefs[i]} not found`);
          }
          return e != null ? e : null;
        });
        ctx.output("entities", finalEntities);
      }
    }
  });
}

const id$1 = "debug:log";
const examples$1 = [
  {
    description: "Write a debug message",
    example: yaml__default["default"].stringify({
      steps: [
        {
          action: id$1,
          id: "write-debug-line",
          name: 'Write "Hello Backstage!" log line',
          input: {
            message: "Hello Backstage!"
          }
        }
      ]
    })
  },
  {
    description: "List the workspace directory",
    example: yaml__default["default"].stringify({
      steps: [
        {
          action: id$1,
          id: "write-workspace-directory",
          name: "List the workspace directory",
          input: {
            listWorkspace: true
          }
        }
      ]
    })
  }
];
function createDebugLogAction() {
  return pluginScaffolderNode.createTemplateAction({
    id: id$1,
    description: "Writes a message into the log or lists all files in the workspace.",
    examples: examples$1,
    schema: {
      input: {
        type: "object",
        properties: {
          message: {
            title: "Message to output.",
            type: "string"
          },
          listWorkspace: {
            title: "List all files in the workspace, if true.",
            type: "boolean"
          },
          extra: {
            title: "Extra info"
          }
        }
      }
    },
    supportsDryRun: true,
    async handler(ctx) {
      var _a, _b;
      ctx.logger.info(JSON.stringify(ctx.input, null, 2));
      if ((_a = ctx.input) == null ? void 0 : _a.message) {
        ctx.logStream.write(ctx.input.message);
      }
      if ((_b = ctx.input) == null ? void 0 : _b.listWorkspace) {
        const files = await recursiveReadDir(ctx.workspacePath);
        ctx.logStream.write(
          `Workspace:
${files.map((f) => `  - ${path.relative(ctx.workspacePath, f)}`).join("\n")}`
        );
      }
    }
  });
}
async function recursiveReadDir(dir) {
  const subdirs = await fs.readdir(dir);
  const files = await Promise.all(
    subdirs.map(async (subdir) => {
      const res = path.join(dir, subdir);
      return (await fs.stat(res)).isDirectory() ? recursiveReadDir(res) : [res];
    })
  );
  return files.reduce((a, f) => a.concat(f), []);
}

const id = "debug:wait";
const MAX_WAIT_TIME_IN_ISO = "T00:00:30";
const examples = [
  {
    description: "Waiting for 5 seconds",
    example: yaml__default["default"].stringify({
      steps: [
        {
          action: id,
          id: "wait-5sec",
          name: "Waiting for 5 seconds",
          input: {
            seconds: 5
          }
        }
      ]
    })
  },
  {
    description: "Waiting for 5 minutes",
    example: yaml__default["default"].stringify({
      steps: [
        {
          action: id,
          id: "wait-5min",
          name: "Waiting for 5 minutes",
          input: {
            minutes: 5
          }
        }
      ]
    })
  }
];
function createWaitAction(options) {
  const toDuration = (maxWaitTime) => {
    if (maxWaitTime) {
      if (maxWaitTime instanceof luxon.Duration) {
        return maxWaitTime;
      }
      return luxon.Duration.fromObject(maxWaitTime);
    }
    return luxon.Duration.fromISOTime(MAX_WAIT_TIME_IN_ISO);
  };
  return pluginScaffolderNode.createTemplateAction({
    id,
    description: "Waits for a certain period of time.",
    examples,
    schema: {
      input: {
        type: "object",
        properties: {
          minutes: {
            title: "Waiting period in minutes.",
            type: "number"
          },
          seconds: {
            title: "Waiting period in seconds.",
            type: "number"
          },
          milliseconds: {
            title: "Waiting period in milliseconds.",
            type: "number"
          }
        }
      }
    },
    async handler(ctx) {
      const delayTime = luxon.Duration.fromObject(ctx.input);
      const maxWait = toDuration(options == null ? void 0 : options.maxWaitTime);
      if (delayTime.minus(maxWait).toMillis() > 0) {
        throw new Error(
          `Waiting duration is longer than the maximum threshold of ${maxWait.toHuman()}`
        );
      }
      await new Promise((resolve) => {
        var _a;
        const controller = new AbortController();
        const timeoutHandle = setTimeout(abort, delayTime.toMillis());
        (_a = ctx.signal) == null ? void 0 : _a.addEventListener("abort", abort);
        function abort() {
          var _a2;
          (_a2 = ctx.signal) == null ? void 0 : _a2.removeEventListener("abort", abort);
          clearTimeout(timeoutHandle);
          controller.abort();
          resolve("finished");
        }
      });
    }
  });
}

async function fetchContents(options) {
  const { reader, integrations, baseUrl, fetchUrl = ".", outputPath } = options;
  const fetchUrlIsAbsolute = isFetchUrlAbsolute(fetchUrl);
  if (!fetchUrlIsAbsolute && (baseUrl == null ? void 0 : baseUrl.startsWith("file://"))) {
    const basePath = baseUrl.slice("file://".length);
    const srcDir = backendCommon.resolveSafeChildPath(path__default["default"].dirname(basePath), fetchUrl);
    await fs__default["default"].copy(srcDir, outputPath);
  } else {
    const readUrl = getReadUrl(fetchUrl, baseUrl, integrations);
    const res = await reader.readTree(readUrl);
    await fs__default["default"].ensureDir(outputPath);
    await res.dir({ targetDir: outputPath });
  }
}
async function fetchFile(options) {
  const { reader, integrations, baseUrl, fetchUrl = ".", outputPath } = options;
  const fetchUrlIsAbsolute = isFetchUrlAbsolute(fetchUrl);
  if (!fetchUrlIsAbsolute && (baseUrl == null ? void 0 : baseUrl.startsWith("file://"))) {
    const basePath = baseUrl.slice("file://".length);
    const src = backendCommon.resolveSafeChildPath(path__default["default"].dirname(basePath), fetchUrl);
    await fs__default["default"].copyFile(src, outputPath);
  } else {
    const readUrl = getReadUrl(fetchUrl, baseUrl, integrations);
    const res = await reader.readUrl(readUrl);
    await fs__default["default"].ensureDir(path__default["default"].dirname(outputPath));
    const buffer = await res.buffer();
    await fs__default["default"].outputFile(outputPath, buffer.toString());
  }
}
function isFetchUrlAbsolute(fetchUrl) {
  let fetchUrlIsAbsolute = false;
  try {
    new URL(fetchUrl);
    fetchUrlIsAbsolute = true;
  } catch {
  }
  return fetchUrlIsAbsolute;
}
function getReadUrl(fetchUrl, baseUrl, integrations) {
  if (isFetchUrlAbsolute(fetchUrl)) {
    return fetchUrl;
  } else if (baseUrl) {
    const integration = integrations.byUrl(baseUrl);
    if (!integration) {
      throw new errors.InputError(`No integration found for location ${baseUrl}`);
    }
    return integration.resolveUrl({
      url: fetchUrl,
      base: baseUrl
    });
  }
  throw new errors.InputError(
    `Failed to fetch, template location could not be determined and the fetch URL is relative, ${fetchUrl}`
  );
}

function createFetchPlainAction(options) {
  const { reader, integrations } = options;
  return pluginScaffolderNode.createTemplateAction({
    id: "fetch:plain",
    description: "Downloads content and places it in the workspace, or optionally in a subdirectory specified by the `targetPath` input option.",
    schema: {
      input: {
        type: "object",
        required: ["url"],
        properties: {
          url: {
            title: "Fetch URL",
            description: "Relative path or absolute URL pointing to the directory tree to fetch",
            type: "string"
          },
          targetPath: {
            title: "Target Path",
            description: "Target path within the working directory to download the contents to.",
            type: "string"
          }
        }
      }
    },
    supportsDryRun: true,
    async handler(ctx) {
      var _a, _b;
      ctx.logger.info("Fetching plain content from remote URL");
      const targetPath = (_a = ctx.input.targetPath) != null ? _a : "./";
      const outputPath = backendCommon.resolveSafeChildPath(ctx.workspacePath, targetPath);
      await fetchContents({
        reader,
        integrations,
        baseUrl: (_b = ctx.templateInfo) == null ? void 0 : _b.baseUrl,
        fetchUrl: ctx.input.url,
        outputPath
      });
    }
  });
}

function createFetchPlainFileAction(options) {
  const { reader, integrations } = options;
  return pluginScaffolderNode.createTemplateAction({
    id: "fetch:plain:file",
    description: "Downloads single file and places it in the workspace.",
    schema: {
      input: {
        type: "object",
        required: ["url", "targetPath"],
        properties: {
          url: {
            title: "Fetch URL",
            description: "Relative path or absolute URL pointing to the single file to fetch.",
            type: "string"
          },
          targetPath: {
            title: "Target Path",
            description: "Target path within the working directory to download the file as.",
            type: "string"
          }
        }
      }
    },
    supportsDryRun: true,
    async handler(ctx) {
      var _a;
      ctx.logger.info("Fetching plain content from remote URL");
      const outputPath = backendCommon.resolveSafeChildPath(
        ctx.workspacePath,
        ctx.input.targetPath
      );
      await fetchFile({
        reader,
        integrations,
        baseUrl: (_a = ctx.templateInfo) == null ? void 0 : _a.baseUrl,
        fetchUrl: ctx.input.url,
        outputPath
      });
    }
  });
}

const mkScript = (nunjucksSource) => `
const { render, renderCompat } = (() => {
  const module = {};
  const process = { env: {} };
  const require = (pkg) => { if (pkg === 'events') { return function (){}; }};

  ${nunjucksSource}

  const env = module.exports.configure({
    autoescape: false,
    tags: {
      variableStart: '\${{',
      variableEnd: '}}',
    },
  });

  const compatEnv = module.exports.configure({
    autoescape: false,
    tags: {
      variableStart: '{{',
      variableEnd: '}}',
    },
  });
  compatEnv.addFilter('jsonify', compatEnv.getFilter('dump'));

  if (typeof templateFilters !== 'undefined') {
    for (const [filterName, filterFn] of Object.entries(templateFilters)) {
      env.addFilter(filterName, (...args) => JSON.parse(filterFn(...args)));
    }
  }

  if (typeof templateGlobals !== 'undefined') {
    for (const [globalName, global] of Object.entries(templateGlobals)) {
      if (typeof global === 'function') {
        env.addGlobal(globalName, (...args) => JSON.parse(global(...args)));
      } else {
        env.addGlobal(globalName, JSON.parse(global));
      }
    }
  }

  let uninstallCompat = undefined;

  function render(str, values) {
    try {
      if (uninstallCompat) {
        uninstallCompat();
        uninstallCompat = undefined;
      }
      return env.renderString(str, JSON.parse(values));
    } catch (error) {
      // Make sure errors don't leak anything
      throw new Error(String(error.message));
    }
  }

  function renderCompat(str, values) {
    try {
      if (!uninstallCompat) {
        uninstallCompat = module.exports.installJinjaCompat();
      }
      return compatEnv.renderString(str, JSON.parse(values));
    } catch (error) {
      // Make sure errors don't leak anything
      throw new Error(String(error.message));
    }
  }

  return { render, renderCompat };
})();
`;
class SecureTemplater {
  static async loadRenderer(options = {}) {
    const { cookiecutterCompat, templateFilters, templateGlobals } = options;
    const sandbox = {};
    if (templateFilters) {
      sandbox.templateFilters = Object.fromEntries(
        Object.entries(templateFilters).filter(([_, filterFunction]) => !!filterFunction).map(([filterName, filterFunction]) => [
          filterName,
          (...args) => JSON.stringify(filterFunction(...args))
        ])
      );
    }
    if (templateGlobals) {
      sandbox.templateGlobals = Object.fromEntries(
        Object.entries(templateGlobals).filter(([_, global]) => !!global).map(([globalName, global]) => {
          if (typeof global === "function") {
            return [
              globalName,
              (...args) => JSON.stringify(global(...args))
            ];
          }
          return [globalName, JSON.stringify(global)];
        })
      );
    }
    const vm = new vm2.VM({ sandbox });
    const nunjucksSource = await fs__default["default"].readFile(
      backendCommon.resolvePackagePath(
        "@backstage/plugin-scaffolder-backend",
        "assets/nunjucks.js.txt"
      ),
      "utf-8"
    );
    vm.run(mkScript(nunjucksSource));
    const render = (template, values) => {
      if (!vm) {
        throw new Error("SecureTemplater has not been initialized");
      }
      vm.setGlobal("templateStr", template);
      vm.setGlobal("templateValues", JSON.stringify(values));
      if (cookiecutterCompat) {
        return vm.run(`renderCompat(templateStr, templateValues)`);
      }
      return vm.run(`render(templateStr, templateValues)`);
    };
    return render;
  }
}

const getRepoSourceDirectory = (workspacePath, sourcePath) => {
  if (sourcePath) {
    const safeSuffix = path.normalize(sourcePath).replace(
      /^(\.\.(\/|\\|$))+/,
      ""
    );
    const path$1 = path.join(workspacePath, safeSuffix);
    if (!backendCommon.isChildPath(workspacePath, path$1)) {
      throw new Error("Invalid source path");
    }
    return path$1;
  }
  return workspacePath;
};
const parseRepoUrl = (repoUrl, integrations) => {
  var _a, _b, _c, _d, _e;
  let parsed;
  try {
    parsed = new URL(`https://${repoUrl}`);
  } catch (error) {
    throw new errors.InputError(
      `Invalid repo URL passed to publisher, got ${repoUrl}, ${error}`
    );
  }
  const host = parsed.host;
  const owner = (_a = parsed.searchParams.get("owner")) != null ? _a : void 0;
  const organization = (_b = parsed.searchParams.get("organization")) != null ? _b : void 0;
  const workspace = (_c = parsed.searchParams.get("workspace")) != null ? _c : void 0;
  const project = (_d = parsed.searchParams.get("project")) != null ? _d : void 0;
  const type = (_e = integrations.byHost(host)) == null ? void 0 : _e.type;
  if (!type) {
    throw new errors.InputError(
      `No matching integration configuration for host ${host}, please check your integrations config`
    );
  }
  const repo = parsed.searchParams.get("repo");
  switch (type) {
    case "bitbucket": {
      if (host === "www.bitbucket.org") {
        checkRequiredParams(parsed, "workspace");
      }
      checkRequiredParams(parsed, "project", "repo");
      break;
    }
    case "gitlab": {
      if (!project) {
        checkRequiredParams(parsed, "owner", "repo");
      }
      break;
    }
    case "gerrit": {
      checkRequiredParams(parsed, "repo");
      break;
    }
    default: {
      checkRequiredParams(parsed, "repo", "owner");
      break;
    }
  }
  return { host, owner, repo, organization, workspace, project };
};
function checkRequiredParams(repoUrl, ...params) {
  for (let i = 0; i < params.length; i++) {
    if (!repoUrl.searchParams.get(params[i])) {
      throw new errors.InputError(
        `Invalid repo URL passed to publisher: ${repoUrl.toString()}, missing ${params[i]}`
      );
    }
  }
}

const createDefaultFilters = ({
  integrations
}) => {
  return {
    parseRepoUrl: (url) => parseRepoUrl(url, integrations),
    parseEntityRef: (ref) => catalogModel.parseEntityRef(ref),
    pick: (obj, key) => get__default["default"](obj, key),
    projectSlug: (repoUrl) => {
      const { owner, repo } = parseRepoUrl(repoUrl, integrations);
      return `${owner}/${repo}`;
    }
  };
};

function createFetchTemplateAction(options) {
  const {
    reader,
    integrations,
    additionalTemplateFilters,
    additionalTemplateGlobals
  } = options;
  const defaultTemplateFilters = createDefaultFilters({ integrations });
  return pluginScaffolderNode.createTemplateAction({
    id: "fetch:template",
    description: "Downloads a skeleton, templates variables into file and directory names and content, and places the result in the workspace, or optionally in a subdirectory specified by the `targetPath` input option.",
    schema: {
      input: {
        type: "object",
        required: ["url"],
        properties: {
          url: {
            title: "Fetch URL",
            description: "Relative path or absolute URL pointing to the directory tree to fetch",
            type: "string"
          },
          targetPath: {
            title: "Target Path",
            description: "Target path within the working directory to download the contents to. Defaults to the working directory root.",
            type: "string"
          },
          values: {
            title: "Template Values",
            description: "Values to pass on to the templating engine",
            type: "object"
          },
          copyWithoutRender: {
            title: "[Deprecated] Copy Without Render",
            description: "An array of glob patterns. Any files or directories which match are copied without being processed as templates.",
            type: "array",
            items: {
              type: "string"
            }
          },
          copyWithoutTemplating: {
            title: "Copy Without Templating",
            description: "An array of glob patterns. Contents of matched files or directories are copied without being processed, but paths are subject to rendering.",
            type: "array",
            items: {
              type: "string"
            }
          },
          cookiecutterCompat: {
            title: "Cookiecutter compatibility mode",
            description: "Enable features to maximise compatibility with templates built for fetch:cookiecutter",
            type: "boolean"
          },
          templateFileExtension: {
            title: "Template File Extension",
            description: "If set, only files with the given extension will be templated. If set to `true`, the default extension `.njk` is used.",
            type: ["string", "boolean"]
          },
          replace: {
            title: "Replace files",
            description: "If set, replace files in targetPath instead of skipping existing ones.",
            type: "boolean"
          }
        }
      }
    },
    supportsDryRun: true,
    async handler(ctx) {
      var _a, _b;
      ctx.logger.info("Fetching template content from remote URL");
      const workDir = await ctx.createTemporaryDirectory();
      const templateDir = backendCommon.resolveSafeChildPath(workDir, "template");
      const targetPath = (_a = ctx.input.targetPath) != null ? _a : "./";
      const outputDir = backendCommon.resolveSafeChildPath(ctx.workspacePath, targetPath);
      if (ctx.input.copyWithoutRender && ctx.input.copyWithoutTemplating) {
        throw new errors.InputError(
          "Fetch action input copyWithoutRender and copyWithoutTemplating can not be used at the same time"
        );
      }
      let copyOnlyPatterns;
      let renderFilename;
      if (ctx.input.copyWithoutRender) {
        ctx.logger.warn(
          "[Deprecated] Please use copyWithoutTemplating instead."
        );
        copyOnlyPatterns = ctx.input.copyWithoutRender;
        renderFilename = false;
      } else {
        copyOnlyPatterns = ctx.input.copyWithoutTemplating;
        renderFilename = true;
      }
      if (copyOnlyPatterns && !Array.isArray(copyOnlyPatterns)) {
        throw new errors.InputError(
          "Fetch action input copyWithoutRender/copyWithoutTemplating must be an Array"
        );
      }
      if (ctx.input.templateFileExtension && (copyOnlyPatterns || ctx.input.cookiecutterCompat)) {
        throw new errors.InputError(
          "Fetch action input extension incompatible with copyWithoutRender/copyWithoutTemplating and cookiecutterCompat"
        );
      }
      let extension = false;
      if (ctx.input.templateFileExtension) {
        extension = ctx.input.templateFileExtension === true ? ".njk" : ctx.input.templateFileExtension;
        if (!extension.startsWith(".")) {
          extension = `.${extension}`;
        }
      }
      await fetchContents({
        reader,
        integrations,
        baseUrl: (_b = ctx.templateInfo) == null ? void 0 : _b.baseUrl,
        fetchUrl: ctx.input.url,
        outputPath: templateDir
      });
      ctx.logger.info("Listing files and directories in template");
      const allEntriesInTemplate = await globby__default["default"](`**/*`, {
        cwd: templateDir,
        dot: true,
        onlyFiles: false,
        markDirectories: true,
        followSymbolicLinks: false
      });
      const nonTemplatedEntries = new Set(
        (await Promise.all(
          (copyOnlyPatterns || []).map(
            (pattern) => globby__default["default"](pattern, {
              cwd: templateDir,
              dot: true,
              onlyFiles: false,
              markDirectories: true,
              followSymbolicLinks: false
            })
          )
        )).flat()
      );
      const { cookiecutterCompat, values } = ctx.input;
      const context = {
        [cookiecutterCompat ? "cookiecutter" : "values"]: values
      };
      ctx.logger.info(
        `Processing ${allEntriesInTemplate.length} template files/directories with input values`,
        ctx.input.values
      );
      const renderTemplate = await SecureTemplater.loadRenderer({
        cookiecutterCompat: ctx.input.cookiecutterCompat,
        templateFilters: {
          ...defaultTemplateFilters,
          ...additionalTemplateFilters
        },
        templateGlobals: additionalTemplateGlobals
      });
      for (const location of allEntriesInTemplate) {
        let renderContents;
        let localOutputPath = location;
        if (extension) {
          renderContents = path.extname(localOutputPath) === extension;
          if (renderContents) {
            localOutputPath = localOutputPath.slice(0, -extension.length);
          }
          localOutputPath = renderTemplate(localOutputPath, context);
        } else {
          renderContents = !nonTemplatedEntries.has(location);
          if (renderFilename) {
            localOutputPath = renderTemplate(localOutputPath, context);
          } else {
            localOutputPath = renderContents ? renderTemplate(localOutputPath, context) : localOutputPath;
          }
        }
        if (containsSkippedContent(localOutputPath)) {
          continue;
        }
        const outputPath = backendCommon.resolveSafeChildPath(outputDir, localOutputPath);
        if (fs__default["default"].existsSync(outputPath) && !ctx.input.replace) {
          continue;
        }
        if (!renderContents && !extension) {
          ctx.logger.info(
            `Copying file/directory ${location} without processing.`
          );
        }
        if (location.endsWith("/")) {
          ctx.logger.info(
            `Writing directory ${location} to template output path.`
          );
          await fs__default["default"].ensureDir(outputPath);
        } else {
          const inputFilePath = backendCommon.resolveSafeChildPath(templateDir, location);
          const stats = await fs__default["default"].promises.lstat(inputFilePath);
          if (stats.isSymbolicLink() || await isbinaryfile.isBinaryFile(inputFilePath)) {
            ctx.logger.info(
              `Copying file binary or symbolic link at ${location}, to template output path.`
            );
            await fs__default["default"].copy(inputFilePath, outputPath);
          } else {
            const statsObj = await fs__default["default"].stat(inputFilePath);
            ctx.logger.info(
              `Writing file ${location} to template output path with mode ${statsObj.mode}.`
            );
            const inputFileContents = await fs__default["default"].readFile(inputFilePath, "utf-8");
            await fs__default["default"].outputFile(
              outputPath,
              renderContents ? renderTemplate(inputFileContents, context) : inputFileContents,
              { mode: statsObj.mode }
            );
          }
        }
      }
      ctx.logger.info(`Template result written to ${outputDir}`);
    }
  });
}
function containsSkippedContent(localOutputPath) {
  return localOutputPath === "" || localOutputPath.startsWith("/") || localOutputPath.includes("//");
}

const createFilesystemDeleteAction = () => {
  return pluginScaffolderNode.createTemplateAction({
    id: "fs:delete",
    description: "Deletes files and directories from the workspace",
    schema: {
      input: {
        required: ["files"],
        type: "object",
        properties: {
          files: {
            title: "Files",
            description: "A list of files and directories that will be deleted",
            type: "array",
            items: {
              type: "string"
            }
          }
        }
      }
    },
    supportsDryRun: true,
    async handler(ctx) {
      var _a;
      if (!Array.isArray((_a = ctx.input) == null ? void 0 : _a.files)) {
        throw new errors.InputError("files must be an Array");
      }
      for (const file of ctx.input.files) {
        const filepath = backendCommon.resolveSafeChildPath(ctx.workspacePath, file);
        try {
          await fs__default["default"].remove(filepath);
          ctx.logger.info(`File ${filepath} deleted successfully`);
        } catch (err) {
          ctx.logger.error(`Failed to delete file ${filepath}:`, err);
          throw err;
        }
      }
    }
  });
};

const createFilesystemRenameAction = () => {
  return pluginScaffolderNode.createTemplateAction({
    id: "fs:rename",
    description: "Renames files and directories within the workspace",
    schema: {
      input: {
        required: ["files"],
        type: "object",
        properties: {
          files: {
            title: "Files",
            description: "A list of file and directory names that will be renamed",
            type: "array",
            items: {
              type: "object",
              required: ["from", "to"],
              properties: {
                from: {
                  type: "string",
                  title: "The source location of the file to be renamed"
                },
                to: {
                  type: "string",
                  title: "The destination of the new file"
                },
                overwrite: {
                  type: "boolean",
                  title: "Overwrite existing file or directory, default is false"
                }
              }
            }
          }
        }
      }
    },
    supportsDryRun: true,
    async handler(ctx) {
      var _a, _b;
      if (!Array.isArray((_a = ctx.input) == null ? void 0 : _a.files)) {
        throw new errors.InputError("files must be an Array");
      }
      for (const file of ctx.input.files) {
        if (!file.from || !file.to) {
          throw new errors.InputError("each file must have a from and to property");
        }
        const sourceFilepath = backendCommon.resolveSafeChildPath(
          ctx.workspacePath,
          file.from
        );
        const destFilepath = backendCommon.resolveSafeChildPath(ctx.workspacePath, file.to);
        try {
          await fs__default["default"].move(sourceFilepath, destFilepath, {
            overwrite: (_b = file.overwrite) != null ? _b : false
          });
          ctx.logger.info(
            `File ${sourceFilepath} renamed to ${destFilepath} successfully`
          );
        } catch (err) {
          ctx.logger.error(
            `Failed to rename file ${sourceFilepath} to ${destFilepath}:`,
            err
          );
          throw err;
        }
      }
    }
  });
};

const executeShellCommand = async (options) => {
  const {
    command,
    args,
    options: spawnOptions,
    logStream = new stream.PassThrough()
  } = options;
  await new Promise((resolve, reject) => {
    const process = child_process.spawn(command, args, spawnOptions);
    process.stdout.on("data", (stream) => {
      logStream.write(stream);
    });
    process.stderr.on("data", (stream) => {
      logStream.write(stream);
    });
    process.on("error", (error) => {
      return reject(error);
    });
    process.on("close", (code) => {
      if (code !== 0) {
        return reject(
          new Error(`Command ${command} failed, exit code: ${code}`)
        );
      }
      return resolve();
    });
  });
};
async function initRepoAndPush({
  dir,
  remoteUrl,
  auth,
  logger,
  defaultBranch = "master",
  commitMessage = "Initial commit",
  gitAuthorInfo
}) {
  var _a, _b;
  const git = backendCommon.Git.fromAuth({
    ...auth,
    logger
  });
  await git.init({
    dir,
    defaultBranch
  });
  await git.add({ dir, filepath: "." });
  const authorInfo = {
    name: (_a = gitAuthorInfo == null ? void 0 : gitAuthorInfo.name) != null ? _a : "Scaffolder",
    email: (_b = gitAuthorInfo == null ? void 0 : gitAuthorInfo.email) != null ? _b : "scaffolder@backstage.io"
  };
  const commitHash = await git.commit({
    dir,
    message: commitMessage,
    author: authorInfo,
    committer: authorInfo
  });
  await git.addRemote({
    dir,
    url: remoteUrl,
    remote: "origin"
  });
  await git.push({
    dir,
    remote: "origin"
  });
  return { commitHash };
}
async function commitAndPushRepo({
  dir,
  auth,
  logger,
  commitMessage,
  gitAuthorInfo,
  branch = "master",
  remoteRef
}) {
  var _a, _b;
  const git = backendCommon.Git.fromAuth({
    ...auth,
    logger
  });
  await git.fetch({ dir });
  await git.checkout({ dir, ref: branch });
  await git.add({ dir, filepath: "." });
  const authorInfo = {
    name: (_a = gitAuthorInfo == null ? void 0 : gitAuthorInfo.name) != null ? _a : "Scaffolder",
    email: (_b = gitAuthorInfo == null ? void 0 : gitAuthorInfo.email) != null ? _b : "scaffolder@backstage.io"
  };
  const commitHash = await git.commit({
    dir,
    message: commitMessage,
    author: authorInfo,
    committer: authorInfo
  });
  await git.push({
    dir,
    remote: "origin",
    remoteRef: remoteRef != null ? remoteRef : `refs/heads/${branch}`
  });
  return { commitHash };
}
const enableBranchProtectionOnDefaultRepoBranch = async ({
  repoName,
  client,
  owner,
  logger,
  requireCodeOwnerReviews,
  bypassPullRequestAllowances,
  requiredApprovingReviewCount,
  restrictions,
  requiredStatusCheckContexts = [],
  requireBranchesToBeUpToDate = true,
  requiredConversationResolution = false,
  defaultBranch = "master",
  enforceAdmins = true,
  dismissStaleReviews = false,
  requiredCommitSigning = false
}) => {
  const tryOnce = async () => {
    try {
      await client.rest.repos.updateBranchProtection({
        mediaType: {
          /**
           * ðŸ‘‡ we need this preview because allowing a custom
           * reviewer count on branch protection is a preview
           * feature
           *
           * More here: https://docs.github.com/en/rest/overview/api-previews#require-multiple-approving-reviews
           */
          previews: ["luke-cage-preview"]
        },
        owner,
        repo: repoName,
        branch: defaultBranch,
        required_status_checks: {
          strict: requireBranchesToBeUpToDate,
          contexts: requiredStatusCheckContexts
        },
        restrictions: restrictions != null ? restrictions : null,
        enforce_admins: enforceAdmins,
        required_pull_request_reviews: {
          required_approving_review_count: requiredApprovingReviewCount,
          require_code_owner_reviews: requireCodeOwnerReviews,
          bypass_pull_request_allowances: bypassPullRequestAllowances,
          dismiss_stale_reviews: dismissStaleReviews
        },
        required_conversation_resolution: requiredConversationResolution
      });
      if (requiredCommitSigning) {
        await client.rest.repos.createCommitSignatureProtection({
          owner,
          repo: repoName,
          branch: defaultBranch
        });
      }
    } catch (e) {
      errors.assertError(e);
      if (e.message.includes(
        "Upgrade to GitHub Pro or make this repository public to enable this feature"
      )) {
        logger.warn(
          "Branch protection was not enabled as it requires GitHub Pro for private repositories"
        );
      } else {
        throw e;
      }
    }
  };
  try {
    await tryOnce();
  } catch (e) {
    if (!e.message.includes("Branch not found")) {
      throw e;
    }
    await new Promise((resolve) => setTimeout(resolve, 600));
    await tryOnce();
  }
};
function entityRefToName(name) {
  return name.replace(/^.*[:/]/g, "");
}

const DEFAULT_TIMEOUT_MS = 6e4;
async function getOctokitOptions(options) {
  var _a;
  const { integrations, credentialsProvider, repoUrl, token } = options;
  const { owner, repo, host } = parseRepoUrl(repoUrl, integrations);
  const requestOptions = {
    // set timeout to 60 seconds
    timeout: DEFAULT_TIMEOUT_MS
  };
  if (!owner) {
    throw new errors.InputError(`No owner provided for repo ${repoUrl}`);
  }
  const integrationConfig = (_a = integrations.github.byHost(host)) == null ? void 0 : _a.config;
  if (!integrationConfig) {
    throw new errors.InputError(`No integration for host ${host}`);
  }
  if (token) {
    return {
      auth: token,
      baseUrl: integrationConfig.apiBaseUrl,
      previews: ["nebula-preview"],
      request: requestOptions
    };
  }
  const githubCredentialsProvider = credentialsProvider != null ? credentialsProvider : integration.DefaultGithubCredentialsProvider.fromIntegrations(integrations);
  const { token: credentialProviderToken } = await githubCredentialsProvider.getCredentials({
    url: `https://${host}/${encodeURIComponent(owner)}/${encodeURIComponent(
      repo
    )}`
  });
  if (!credentialProviderToken) {
    throw new errors.InputError(
      `No token available for host: ${host}, with owner ${owner}, and repo ${repo}`
    );
  }
  return {
    auth: credentialProviderToken,
    baseUrl: integrationConfig.apiBaseUrl,
    previews: ["nebula-preview"]
  };
}
async function createGithubRepoWithCollaboratorsAndTopics(client, repo, owner, repoVisibility, description, homepage, deleteBranchOnMerge, allowMergeCommit, allowSquashMerge, squashMergeCommitTitle, squashMergeCommitMessage, allowRebaseMerge, allowAutoMerge, access, collaborators, hasProjects, hasWiki, hasIssues, topics, logger) {
  const user = await client.rest.users.getByUsername({
    username: owner
  });
  if (access == null ? void 0 : access.startsWith(`${owner}/`)) {
    await validateAccessTeam(client, access);
  }
  const repoCreationPromise = user.data.type === "Organization" ? client.rest.repos.createInOrg({
    name: repo,
    org: owner,
    private: repoVisibility === "private",
    visibility: repoVisibility,
    description,
    delete_branch_on_merge: deleteBranchOnMerge,
    allow_merge_commit: allowMergeCommit,
    allow_squash_merge: allowSquashMerge,
    squash_merge_commit_title: squashMergeCommitTitle,
    squash_merge_commit_message: squashMergeCommitMessage,
    allow_rebase_merge: allowRebaseMerge,
    allow_auto_merge: allowAutoMerge,
    homepage,
    has_projects: hasProjects,
    has_wiki: hasWiki,
    has_issues: hasIssues
  }) : client.rest.repos.createForAuthenticatedUser({
    name: repo,
    private: repoVisibility === "private",
    description,
    delete_branch_on_merge: deleteBranchOnMerge,
    allow_merge_commit: allowMergeCommit,
    allow_squash_merge: allowSquashMerge,
    squash_merge_commit_title: squashMergeCommitTitle,
    squash_merge_commit_message: squashMergeCommitMessage,
    allow_rebase_merge: allowRebaseMerge,
    allow_auto_merge: allowAutoMerge,
    homepage,
    has_projects: hasProjects,
    has_wiki: hasWiki,
    has_issues: hasIssues
  });
  let newRepo;
  try {
    newRepo = (await repoCreationPromise).data;
  } catch (e) {
    errors.assertError(e);
    if (e.message === "Resource not accessible by integration") {
      logger.warn(
        `The GitHub app or token provided may not have the required permissions to create the ${user.data.type} repository ${owner}/${repo}.`
      );
    }
    throw new Error(
      `Failed to create the ${user.data.type} repository ${owner}/${repo}, ${e.message}`
    );
  }
  if (access == null ? void 0 : access.startsWith(`${owner}/`)) {
    const [, team] = access.split("/");
    await client.rest.teams.addOrUpdateRepoPermissionsInOrg({
      org: owner,
      team_slug: team,
      owner,
      repo,
      permission: "admin"
    });
  } else if (access && access !== owner) {
    await client.rest.repos.addCollaborator({
      owner,
      repo,
      username: access,
      permission: "admin"
    });
  }
  if (collaborators) {
    for (const collaborator of collaborators) {
      try {
        if ("user" in collaborator) {
          await client.rest.repos.addCollaborator({
            owner,
            repo,
            username: entityRefToName(collaborator.user),
            permission: collaborator.access
          });
        } else if ("team" in collaborator) {
          await client.rest.teams.addOrUpdateRepoPermissionsInOrg({
            org: owner,
            team_slug: entityRefToName(collaborator.team),
            owner,
            repo,
            permission: collaborator.access
          });
        }
      } catch (e) {
        errors.assertError(e);
        const name = extractCollaboratorName(collaborator);
        logger.warn(
          `Skipping ${collaborator.access} access for ${name}, ${e.message}`
        );
      }
    }
  }
  if (topics) {
    try {
      await client.rest.repos.replaceAllTopics({
        owner,
        repo,
        names: topics.map((t) => t.toLowerCase())
      });
    } catch (e) {
      errors.assertError(e);
      logger.warn(`Skipping topics ${topics.join(" ")}, ${e.message}`);
    }
  }
  return newRepo;
}
async function initRepoPushAndProtect(remoteUrl, password, workspacePath, sourcePath, defaultBranch, protectDefaultBranch, protectEnforceAdmins, owner, client, repo, requireCodeOwnerReviews, bypassPullRequestAllowances, requiredApprovingReviewCount, restrictions, requiredStatusCheckContexts, requireBranchesToBeUpToDate, requiredConversationResolution, config, logger, gitCommitMessage, gitAuthorName, gitAuthorEmail, dismissStaleReviews, requiredCommitSigning) {
  const gitAuthorInfo = {
    name: gitAuthorName ? gitAuthorName : config.getOptionalString("scaffolder.defaultAuthor.name"),
    email: gitAuthorEmail ? gitAuthorEmail : config.getOptionalString("scaffolder.defaultAuthor.email")
  };
  const commitMessage = gitCommitMessage ? gitCommitMessage : config.getOptionalString("scaffolder.defaultCommitMessage");
  const commitResult = await initRepoAndPush({
    dir: getRepoSourceDirectory(workspacePath, sourcePath),
    remoteUrl,
    defaultBranch,
    auth: {
      username: "x-access-token",
      password
    },
    logger,
    commitMessage,
    gitAuthorInfo
  });
  if (protectDefaultBranch) {
    try {
      await enableBranchProtectionOnDefaultRepoBranch({
        owner,
        client,
        repoName: repo,
        logger,
        defaultBranch,
        bypassPullRequestAllowances,
        requiredApprovingReviewCount,
        restrictions,
        requireCodeOwnerReviews,
        requiredStatusCheckContexts,
        requireBranchesToBeUpToDate,
        requiredConversationResolution,
        enforceAdmins: protectEnforceAdmins,
        dismissStaleReviews,
        requiredCommitSigning
      });
    } catch (e) {
      errors.assertError(e);
      logger.warn(
        `Skipping: default branch protection on '${repo}', ${e.message}`
      );
    }
  }
  return { commitHash: commitResult.commitHash };
}
function extractCollaboratorName(collaborator) {
  if ("username" in collaborator)
    return collaborator.username;
  if ("user" in collaborator)
    return collaborator.user;
  return collaborator.team;
}
async function validateAccessTeam(client, access) {
  const [org, team_slug] = access.split("/");
  try {
    await client.rest.teams.getByName({
      org,
      team_slug
    });
  } catch (e) {
    if (e.response.data.message === "Not Found") {
      const message = `Received 'Not Found' from the API; one of org:
        ${org} or team: ${team_slug} was not found within GitHub.`;
      throw new errors.NotFoundError(message);
    }
  }
}

function createGithubActionsDispatchAction(options) {
  const { integrations, githubCredentialsProvider } = options;
  return pluginScaffolderNode.createTemplateAction({
    id: "github:actions:dispatch",
    description: "Dispatches a GitHub Action workflow for a given branch or tag",
    schema: {
      input: {
        type: "object",
        required: ["repoUrl", "workflowId", "branchOrTagName"],
        properties: {
          repoUrl: {
            title: "Repository Location",
            description: `Accepts the format 'github.com?repo=reponame&owner=owner' where 'reponame' is the new repository name and 'owner' is an organization or username`,
            type: "string"
          },
          workflowId: {
            title: "Workflow ID",
            description: "The GitHub Action Workflow filename",
            type: "string"
          },
          branchOrTagName: {
            title: "Branch or Tag name",
            description: "The git branch or tag name used to dispatch the workflow",
            type: "string"
          },
          workflowInputs: {
            title: "Workflow Inputs",
            description: "Inputs keys and values to send to GitHub Action configured on the workflow file. The maximum number of properties is 10. ",
            type: "object"
          },
          token: {
            title: "Authentication Token",
            type: "string",
            description: "The GITHUB_TOKEN to use for authorization to GitHub"
          }
        }
      }
    },
    async handler(ctx) {
      const {
        repoUrl,
        workflowId,
        branchOrTagName,
        workflowInputs,
        token: providedToken
      } = ctx.input;
      ctx.logger.info(
        `Dispatching workflow ${workflowId} for repo ${repoUrl} on ${branchOrTagName}`
      );
      const { owner, repo } = parseRepoUrl(repoUrl, integrations);
      if (!owner) {
        throw new errors.InputError("Invalid repository owner provided in repoUrl");
      }
      const client = new octokit.Octokit(
        await getOctokitOptions({
          integrations,
          repoUrl,
          credentialsProvider: githubCredentialsProvider,
          token: providedToken
        })
      );
      await client.rest.actions.createWorkflowDispatch({
        owner,
        repo,
        workflow_id: workflowId,
        ref: branchOrTagName,
        inputs: workflowInputs
      });
      ctx.logger.info(`Workflow ${workflowId} dispatched successfully`);
    }
  });
}

function createGithubIssuesLabelAction(options) {
  const { integrations, githubCredentialsProvider } = options;
  return pluginScaffolderNode.createTemplateAction({
    id: "github:issues:label",
    description: "Adds labels to a pull request or issue on GitHub.",
    schema: {
      input: {
        type: "object",
        required: ["repoUrl", "number", "labels"],
        properties: {
          repoUrl: {
            title: "Repository Location",
            description: `Accepts the format 'github.com?repo=reponame&owner=owner' where 'reponame' is the repository name and 'owner' is an organization or username`,
            type: "string"
          },
          number: {
            title: "Pull Request or issue number",
            description: "The pull request or issue number to add labels to",
            type: "number"
          },
          labels: {
            title: "Labels",
            description: "The labels to add to the pull request or issue",
            type: "array",
            items: {
              type: "string"
            }
          },
          token: {
            title: "Authentication Token",
            type: "string",
            description: "The GITHUB_TOKEN to use for authorization to GitHub"
          }
        }
      }
    },
    async handler(ctx) {
      const { repoUrl, number, labels, token: providedToken } = ctx.input;
      const { owner, repo } = parseRepoUrl(repoUrl, integrations);
      ctx.logger.info(`Adding labels to ${number} issue on repo ${repo}`);
      if (!owner) {
        throw new errors.InputError("Invalid repository owner provided in repoUrl");
      }
      const client = new octokit.Octokit(
        await getOctokitOptions({
          integrations,
          credentialsProvider: githubCredentialsProvider,
          repoUrl,
          token: providedToken
        })
      );
      try {
        await client.rest.issues.addLabels({
          owner,
          repo,
          issue_number: number,
          labels
        });
      } catch (e) {
        errors.assertError(e);
        ctx.logger.warn(
          `Failed: adding labels to issue: '${number}' on repo: '${repo}', ${e.message}`
        );
      }
    }
  });
}

const repoUrl = {
  title: "Repository Location",
  description: `Accepts the format 'github.com?repo=reponame&owner=owner' where 'reponame' is the new repository name and 'owner' is an organization or username`,
  type: "string"
};
const description = {
  title: "Repository Description",
  type: "string"
};
const homepage = {
  title: "Repository Homepage",
  type: "string"
};
const access = {
  title: "Repository Access",
  description: `Sets an admin collaborator on the repository. Can either be a user reference different from 'owner' in 'repoUrl' or team reference, eg. 'org/team-name'`,
  type: "string"
};
const requireCodeOwnerReviews = {
  title: "Require CODEOWNER Reviews?",
  description: "Require an approved review in PR including files with a designated Code Owner",
  type: "boolean"
};
const dismissStaleReviews = {
  title: "Dismiss Stale Reviews",
  description: "New reviewable commits pushed to a matching branch will dismiss pull request review approvals.",
  type: "boolean"
};
const requiredStatusCheckContexts = {
  title: "Required Status Check Contexts",
  description: "The list of status checks to require in order to merge into this branch",
  type: "array",
  items: {
    type: "string"
  }
};
const requireBranchesToBeUpToDate = {
  title: "Require Branches To Be Up To Date?",
  description: `Require branches to be up to date before merging. The default value is 'true'`,
  type: "boolean"
};
const requiredConversationResolution = {
  title: "Required Conversation Resolution",
  description: "Requires all conversations on code to be resolved before a pull request can be merged into this branch",
  type: "boolean"
};
const repoVisibility = {
  title: "Repository Visibility",
  type: "string",
  enum: ["private", "public", "internal"]
};
const deleteBranchOnMerge = {
  title: "Delete Branch On Merge",
  type: "boolean",
  description: `Delete the branch after merging the PR. The default value is 'false'`
};
const gitAuthorName = {
  title: "Default Author Name",
  type: "string",
  description: `Sets the default author name for the commit. The default value is 'Scaffolder'`
};
const gitAuthorEmail = {
  title: "Default Author Email",
  type: "string",
  description: `Sets the default author email for the commit.`
};
const allowMergeCommit = {
  title: "Allow Merge Commits",
  type: "boolean",
  description: `Allow merge commits. The default value is 'true'`
};
const allowSquashMerge = {
  title: "Allow Squash Merges",
  type: "boolean",
  description: `Allow squash merges. The default value is 'true'`
};
const squashMergeCommitTitle = {
  title: "Default squash merge commit title",
  enum: ["PR_TITLE", "COMMIT_OR_PR_TITLE"],
  description: `Sets the default value for a squash merge commit title. The default value is 'COMMIT_OR_PR_TITLE'`
};
const squashMergeCommitMessage = {
  title: "Default squash merge commit message",
  enum: ["PR_BODY", "COMMIT_MESSAGES", "BLANK"],
  description: `Sets the default value for a squash merge commit message. The default value is 'COMMIT_MESSAGES'`
};
const allowRebaseMerge = {
  title: "Allow Rebase Merges",
  type: "boolean",
  description: `Allow rebase merges. The default value is 'true'`
};
const allowAutoMerge = {
  title: "Allow Auto Merges",
  type: "boolean",
  description: `Allow individual PRs to merge automatically when all merge requirements are met. The default value is 'false'`
};
const collaborators = {
  title: "Collaborators",
  description: "Provide additional users or teams with permissions",
  type: "array",
  items: {
    type: "object",
    additionalProperties: false,
    required: ["access"],
    properties: {
      access: {
        type: "string",
        description: "The type of access for the user"
      },
      user: {
        type: "string",
        description: "The name of the user that will be added as a collaborator"
      },
      team: {
        type: "string",
        description: "The name of the team that will be added as a collaborator"
      }
    },
    oneOf: [{ required: ["user"] }, { required: ["team"] }]
  }
};
const hasProjects = {
  title: "Enable projects",
  type: "boolean",
  description: `Enable projects for the repository. The default value is 'true' unless the organization has disabled repository projects`
};
const hasWiki = {
  title: "Enable the wiki",
  type: "boolean",
  description: `Enable the wiki for the repository. The default value is 'true'`
};
const hasIssues = {
  title: "Enable issues",
  type: "boolean",
  description: `Enable issues for the repository. The default value is 'true'`
};
const token = {
  title: "Authentication Token",
  type: "string",
  description: "The token to use for authorization to GitHub"
};
const topics = {
  title: "Topics",
  type: "array",
  items: {
    type: "string"
  }
};
const defaultBranch = {
  title: "Default Branch",
  type: "string",
  description: `Sets the default branch on the repository. The default value is 'master'`
};
const protectDefaultBranch = {
  title: "Protect Default Branch",
  type: "boolean",
  description: `Protect the default branch after creating the repository. The default value is 'true'`
};
const protectEnforceAdmins = {
  title: "Enforce Admins On Protected Branches",
  type: "boolean",
  description: `Enforce admins to adhere to default branch protection. The default value is 'true'`
};
const bypassPullRequestAllowances = {
  title: "Bypass pull request requirements",
  description: "Allow specific users, teams, or apps to bypass pull request requirements.",
  type: "object",
  additionalProperties: false,
  properties: {
    apps: {
      type: "array",
      items: {
        type: "string"
      }
    },
    users: {
      type: "array",
      items: {
        type: "string"
      }
    },
    teams: {
      type: "array",
      items: {
        type: "string"
      }
    }
  }
};
const gitCommitMessage = {
  title: "Git Commit Message",
  type: "string",
  description: `Sets the commit message on the repository. The default value is 'initial commit'`
};
const sourcePath = {
  title: "Source Path",
  description: "Path within the workspace that will be used as the repository root. If omitted, the entire workspace will be published as the repository.",
  type: "string"
};
const requiredApprovingReviewCount = {
  title: "Required approving review count",
  type: "number",
  description: `Specify the number of reviewers required to approve pull requests. Use a number between 1 and 6 or 0 to not require reviewers. Defaults to 1.`
};
const restrictions = {
  title: "Restrict who can push to the protected branch",
  description: "Restrict who can push to the protected branch. User, app, and team restrictions are only available for organization-owned repositories.",
  type: "object",
  additionalProperties: false,
  properties: {
    apps: {
      type: "array",
      items: {
        type: "string"
      }
    },
    users: {
      type: "array",
      items: {
        type: "string"
      }
    },
    teams: {
      type: "array",
      items: {
        type: "string"
      }
    }
  }
};
const requiredCommitSigning = {
  title: "Require commit signing",
  type: "boolean",
  description: `Require commit signing so that you must sign commits on this branch.`
};

const remoteUrl = {
  title: "A URL to the repository with the provider",
  type: "string"
};
const repoContentsUrl = {
  title: "A URL to the root of the repository",
  type: "string"
};
const commitHash = {
  title: "The git commit hash of the initial commit",
  type: "string"
};

function createGithubRepoCreateAction(options) {
  const { integrations, githubCredentialsProvider } = options;
  return pluginScaffolderNode.createTemplateAction({
    id: "github:repo:create",
    description: "Creates a GitHub repository.",
    schema: {
      input: {
        type: "object",
        required: ["repoUrl"],
        properties: {
          repoUrl: repoUrl,
          description: description,
          homepage: homepage,
          access: access,
          requireCodeOwnerReviews: requireCodeOwnerReviews,
          bypassPullRequestAllowances: bypassPullRequestAllowances,
          requiredApprovingReviewCount: requiredApprovingReviewCount,
          restrictions: restrictions,
          requiredStatusCheckContexts: requiredStatusCheckContexts,
          requireBranchesToBeUpToDate: requireBranchesToBeUpToDate,
          requiredConversationResolution: requiredConversationResolution,
          repoVisibility: repoVisibility,
          deleteBranchOnMerge: deleteBranchOnMerge,
          allowMergeCommit: allowMergeCommit,
          allowSquashMerge: allowSquashMerge,
          squashMergeCommitTitle: squashMergeCommitTitle,
          squashMergeCommitMessage: squashMergeCommitMessage,
          allowRebaseMerge: allowRebaseMerge,
          allowAutoMerge: allowAutoMerge,
          collaborators: collaborators,
          hasProjects: hasProjects,
          hasWiki: hasWiki,
          hasIssues: hasIssues,
          token: token,
          topics: topics,
          requiredCommitSigning: requiredCommitSigning
        }
      },
      output: {
        type: "object",
        properties: {
          remoteUrl: remoteUrl,
          repoContentsUrl: repoContentsUrl
        }
      }
    },
    async handler(ctx) {
      const {
        repoUrl,
        description,
        homepage,
        access,
        repoVisibility = "private",
        deleteBranchOnMerge = false,
        allowMergeCommit = true,
        allowSquashMerge = true,
        squashMergeCommitTitle = "COMMIT_OR_PR_TITLE",
        squashMergeCommitMessage = "COMMIT_MESSAGES",
        allowRebaseMerge = true,
        allowAutoMerge = false,
        collaborators,
        hasProjects = void 0,
        hasWiki = void 0,
        hasIssues = void 0,
        topics,
        token: providedToken
      } = ctx.input;
      const octokitOptions = await getOctokitOptions({
        integrations,
        credentialsProvider: githubCredentialsProvider,
        token: providedToken,
        repoUrl
      });
      const client = new octokit.Octokit(octokitOptions);
      const { owner, repo } = parseRepoUrl(repoUrl, integrations);
      if (!owner) {
        throw new errors.InputError("Invalid repository owner provided in repoUrl");
      }
      const newRepo = await createGithubRepoWithCollaboratorsAndTopics(
        client,
        repo,
        owner,
        repoVisibility,
        description,
        homepage,
        deleteBranchOnMerge,
        allowMergeCommit,
        allowSquashMerge,
        squashMergeCommitTitle,
        squashMergeCommitMessage,
        allowRebaseMerge,
        allowAutoMerge,
        access,
        collaborators,
        hasProjects,
        hasWiki,
        hasIssues,
        topics,
        ctx.logger
      );
      ctx.output("remoteUrl", newRepo.clone_url);
    }
  });
}

function createGithubRepoPushAction(options) {
  const { integrations, config, githubCredentialsProvider } = options;
  return pluginScaffolderNode.createTemplateAction({
    id: "github:repo:push",
    description: "Initializes a git repository of contents in workspace and publishes it to GitHub.",
    schema: {
      input: {
        type: "object",
        required: ["repoUrl"],
        properties: {
          repoUrl: repoUrl,
          requireCodeOwnerReviews: requireCodeOwnerReviews,
          dismissStaleReviews: dismissStaleReviews,
          requiredStatusCheckContexts: requiredStatusCheckContexts,
          bypassPullRequestAllowances: bypassPullRequestAllowances,
          requiredApprovingReviewCount: requiredApprovingReviewCount,
          restrictions: restrictions,
          requireBranchesToBeUpToDate: requireBranchesToBeUpToDate,
          requiredConversationResolution: requiredConversationResolution,
          defaultBranch: defaultBranch,
          protectDefaultBranch: protectDefaultBranch,
          protectEnforceAdmins: protectEnforceAdmins,
          gitCommitMessage: gitCommitMessage,
          gitAuthorName: gitAuthorName,
          gitAuthorEmail: gitAuthorEmail,
          sourcePath: sourcePath,
          token: token,
          requiredCommitSigning: requiredCommitSigning
        }
      },
      output: {
        type: "object",
        properties: {
          remoteUrl: remoteUrl,
          repoContentsUrl: repoContentsUrl,
          commitHash: commitHash
        }
      }
    },
    async handler(ctx) {
      const {
        repoUrl,
        defaultBranch = "master",
        protectDefaultBranch = true,
        protectEnforceAdmins = true,
        gitCommitMessage = "initial commit",
        gitAuthorName,
        gitAuthorEmail,
        requireCodeOwnerReviews = false,
        dismissStaleReviews = false,
        bypassPullRequestAllowances,
        requiredApprovingReviewCount = 1,
        restrictions,
        requiredStatusCheckContexts = [],
        requireBranchesToBeUpToDate = true,
        requiredConversationResolution = false,
        token: providedToken,
        requiredCommitSigning = false
      } = ctx.input;
      const { owner, repo } = parseRepoUrl(repoUrl, integrations);
      if (!owner) {
        throw new errors.InputError("Invalid repository owner provided in repoUrl");
      }
      const octokitOptions = await getOctokitOptions({
        integrations,
        credentialsProvider: githubCredentialsProvider,
        token: providedToken,
        repoUrl
      });
      const client = new octokit.Octokit(octokitOptions);
      const targetRepo = await client.rest.repos.get({ owner, repo });
      const remoteUrl = targetRepo.data.clone_url;
      const repoContentsUrl = `${targetRepo.data.html_url}/blob/${defaultBranch}`;
      const { commitHash } = await initRepoPushAndProtect(
        remoteUrl,
        octokitOptions.auth,
        ctx.workspacePath,
        ctx.input.sourcePath,
        defaultBranch,
        protectDefaultBranch,
        protectEnforceAdmins,
        owner,
        client,
        repo,
        requireCodeOwnerReviews,
        bypassPullRequestAllowances,
        requiredApprovingReviewCount,
        restrictions,
        requiredStatusCheckContexts,
        requireBranchesToBeUpToDate,
        requiredConversationResolution,
        config,
        ctx.logger,
        gitCommitMessage,
        gitAuthorName,
        gitAuthorEmail,
        dismissStaleReviews,
        requiredCommitSigning
      );
      ctx.output("remoteUrl", remoteUrl);
      ctx.output("repoContentsUrl", repoContentsUrl);
      ctx.output("commitHash", commitHash);
    }
  });
}

function createGithubWebhookAction(options) {
  const { integrations, defaultWebhookSecret, githubCredentialsProvider } = options;
  const eventNames = webhooks.emitterEventNames.filter((event) => !event.includes("."));
  return pluginScaffolderNode.createTemplateAction({
    id: "github:webhook",
    description: "Creates webhook for a repository on GitHub.",
    schema: {
      input: {
        type: "object",
        required: ["repoUrl", "webhookUrl"],
        properties: {
          repoUrl: {
            title: "Repository Location",
            description: `Accepts the format 'github.com?repo=reponame&owner=owner' where 'reponame' is the new repository name and 'owner' is an organization or username`,
            type: "string"
          },
          webhookUrl: {
            title: "Webhook URL",
            description: "The URL to which the payloads will be delivered",
            type: "string"
          },
          webhookSecret: {
            title: "Webhook Secret",
            description: "Webhook secret value. The default can be provided internally in action creation",
            type: "string"
          },
          events: {
            title: "Triggering Events",
            description: "Determines what events the hook is triggered for. Default: push",
            type: "array",
            oneOf: [
              {
                items: {
                  type: "string",
                  enum: eventNames
                }
              },
              {
                items: {
                  type: "string",
                  const: "*"
                }
              }
            ]
          },
          active: {
            title: "Active",
            type: "boolean",
            description: `Determines if notifications are sent when the webhook is triggered. Default: true`
          },
          contentType: {
            title: "Content Type",
            type: "string",
            enum: ["form", "json"],
            description: `The media type used to serialize the payloads. The default is 'form'`
          },
          insecureSsl: {
            title: "Insecure SSL",
            type: "boolean",
            description: `Determines whether the SSL certificate of the host for url will be verified when delivering payloads. Default 'false'`
          },
          token: {
            title: "Authentication Token",
            type: "string",
            description: "The GITHUB_TOKEN to use for authorization to GitHub"
          }
        }
      }
    },
    async handler(ctx) {
      const {
        repoUrl,
        webhookUrl,
        webhookSecret = defaultWebhookSecret,
        events = ["push"],
        active = true,
        contentType = "form",
        insecureSsl = false,
        token: providedToken
      } = ctx.input;
      ctx.logger.info(`Creating webhook ${webhookUrl} for repo ${repoUrl}`);
      const { owner, repo } = parseRepoUrl(repoUrl, integrations);
      if (!owner) {
        throw new errors.InputError("Invalid repository owner provided in repoUrl");
      }
      const client = new octokit.Octokit(
        await getOctokitOptions({
          integrations,
          credentialsProvider: githubCredentialsProvider,
          repoUrl,
          token: providedToken
        })
      );
      try {
        const insecure_ssl = insecureSsl ? "1" : "0";
        await client.rest.repos.createWebhook({
          owner,
          repo,
          config: {
            url: webhookUrl,
            content_type: contentType,
            secret: webhookSecret,
            insecure_ssl
          },
          events,
          active
        });
        ctx.logger.info(`Webhook '${webhookUrl}' created successfully`);
      } catch (e) {
        errors.assertError(e);
        ctx.logger.warn(
          `Failed: create webhook '${webhookUrl}' on repo: '${repo}', ${e.message}`
        );
      }
    }
  });
}

function createPublishAzureAction(options) {
  const { integrations, config } = options;
  return pluginScaffolderNode.createTemplateAction({
    id: "publish:azure",
    description: "Initializes a git repository of the content in the workspace, and publishes it to Azure.",
    schema: {
      input: {
        type: "object",
        required: ["repoUrl"],
        properties: {
          repoUrl: {
            title: "Repository Location",
            type: "string"
          },
          description: {
            title: "Repository Description",
            type: "string"
          },
          defaultBranch: {
            title: "Default Branch",
            type: "string",
            description: `Sets the default branch on the repository. The default value is 'master'`
          },
          gitCommitMessage: {
            title: "Git Commit Message",
            type: "string",
            description: `Sets the commit message on the repository. The default value is 'initial commit'`
          },
          gitAuthorName: {
            title: "Default Author Name",
            type: "string",
            description: `Sets the default author name for the commit. The default value is 'Scaffolder'`
          },
          gitAuthorEmail: {
            title: "Default Author Email",
            type: "string",
            description: `Sets the default author email for the commit.`
          },
          sourcePath: {
            title: "Source Path",
            description: "Path within the workspace that will be used as the repository root. If omitted, the entire workspace will be published as the repository.",
            type: "string"
          },
          token: {
            title: "Authentication Token",
            type: "string",
            description: "The token to use for authorization to Azure"
          }
        }
      },
      output: {
        type: "object",
        properties: {
          remoteUrl: {
            title: "A URL to the repository with the provider",
            type: "string"
          },
          repoContentsUrl: {
            title: "A URL to the root of the repository",
            type: "string"
          },
          repositoryId: {
            title: "The Id of the created repository",
            type: "string"
          },
          commitHash: {
            title: "The git commit hash of the initial commit",
            type: "string"
          }
        }
      }
    },
    async handler(ctx) {
      var _a;
      const {
        repoUrl,
        defaultBranch = "master",
        gitCommitMessage = "initial commit",
        gitAuthorName,
        gitAuthorEmail
      } = ctx.input;
      const { owner, repo, host, organization } = parseRepoUrl(
        repoUrl,
        integrations
      );
      if (!organization) {
        throw new errors.InputError(
          `Invalid URL provider was included in the repo URL to create ${ctx.input.repoUrl}, missing organization`
        );
      }
      const integrationConfig = integrations.azure.byHost(host);
      if (!integrationConfig) {
        throw new errors.InputError(
          `No matching integration configuration for host ${host}, please check your integrations config`
        );
      }
      if (!integrationConfig.config.token && !ctx.input.token) {
        throw new errors.InputError(`No token provided for Azure Integration ${host}`);
      }
      const token = (_a = ctx.input.token) != null ? _a : integrationConfig.config.token;
      const authHandler = azureDevopsNodeApi.getPersonalAccessTokenHandler(token);
      const webApi = new azureDevopsNodeApi.WebApi(`https://${host}/${organization}`, authHandler);
      const client = await webApi.getGitApi();
      const createOptions = { name: repo };
      const returnedRepo = await client.createRepository(createOptions, owner);
      if (!returnedRepo) {
        throw new errors.InputError(
          `Unable to create the repository with Organization ${organization}, Project ${owner} and Repo ${repo}.
          Please make sure that both the Org and Project are typed corrected and exist.`
        );
      }
      const remoteUrl = returnedRepo.remoteUrl;
      if (!remoteUrl) {
        throw new errors.InputError(
          "No remote URL returned from create repository for Azure"
        );
      }
      const repositoryId = returnedRepo.id;
      if (!repositoryId) {
        throw new errors.InputError("No Id returned from create repository for Azure");
      }
      const repoContentsUrl = remoteUrl;
      const gitAuthorInfo = {
        name: gitAuthorName ? gitAuthorName : config.getOptionalString("scaffolder.defaultAuthor.name"),
        email: gitAuthorEmail ? gitAuthorEmail : config.getOptionalString("scaffolder.defaultAuthor.email")
      };
      const commitResult = await initRepoAndPush({
        dir: getRepoSourceDirectory(ctx.workspacePath, ctx.input.sourcePath),
        remoteUrl,
        defaultBranch,
        auth: {
          username: "notempty",
          password: token
        },
        logger: ctx.logger,
        commitMessage: gitCommitMessage ? gitCommitMessage : config.getOptionalString("scaffolder.defaultCommitMessage"),
        gitAuthorInfo
      });
      ctx.output("commitHash", commitResult == null ? void 0 : commitResult.commitHash);
      ctx.output("remoteUrl", remoteUrl);
      ctx.output("repoContentsUrl", repoContentsUrl);
      ctx.output("repositoryId", repositoryId);
    }
  });
}

const createBitbucketCloudRepository = async (opts) => {
  const {
    workspace,
    project,
    repo,
    description,
    repoVisibility,
    mainBranch,
    authorization,
    apiBaseUrl
  } = opts;
  const options = {
    method: "POST",
    body: JSON.stringify({
      scm: "git",
      description,
      is_private: repoVisibility === "private",
      project: { key: project }
    }),
    headers: {
      Authorization: authorization,
      "Content-Type": "application/json"
    }
  };
  let response;
  try {
    response = await fetch__default["default"](
      `${apiBaseUrl}/repositories/${workspace}/${repo}`,
      options
    );
  } catch (e) {
    throw new Error(`Unable to create repository, ${e}`);
  }
  if (response.status !== 200) {
    throw new Error(
      `Unable to create repository, ${response.status} ${response.statusText}, ${await response.text()}`
    );
  }
  const r = await response.json();
  let remoteUrl = "";
  for (const link of r.links.clone) {
    if (link.name === "https") {
      remoteUrl = link.href;
    }
  }
  const repoContentsUrl = `${r.links.html.href}/src/${mainBranch}`;
  return { remoteUrl, repoContentsUrl };
};
const createBitbucketServerRepository = async (opts) => {
  const {
    project,
    repo,
    description,
    authorization,
    repoVisibility,
    apiBaseUrl
  } = opts;
  let response;
  const options = {
    method: "POST",
    body: JSON.stringify({
      name: repo,
      description,
      public: repoVisibility === "public"
    }),
    headers: {
      Authorization: authorization,
      "Content-Type": "application/json"
    }
  };
  try {
    response = await fetch__default["default"](`${apiBaseUrl}/projects/${project}/repos`, options);
  } catch (e) {
    throw new Error(`Unable to create repository, ${e}`);
  }
  if (response.status !== 201) {
    throw new Error(
      `Unable to create repository, ${response.status} ${response.statusText}, ${await response.text()}`
    );
  }
  const r = await response.json();
  let remoteUrl = "";
  for (const link of r.links.clone) {
    if (link.name === "http") {
      remoteUrl = link.href;
    }
  }
  const repoContentsUrl = `${r.links.self[0].href}`;
  return { remoteUrl, repoContentsUrl };
};
const getAuthorizationHeader$1 = (config) => {
  if (config.username && config.appPassword) {
    const buffer = Buffer.from(
      `${config.username}:${config.appPassword}`,
      "utf8"
    );
    return `Basic ${buffer.toString("base64")}`;
  }
  if (config.token) {
    return `Bearer ${config.token}`;
  }
  throw new Error(
    `Authorization has not been provided for Bitbucket. Please add either username + appPassword or token to the Integrations config`
  );
};
const performEnableLFS$1 = async (opts) => {
  const { authorization, host, project, repo } = opts;
  const options = {
    method: "PUT",
    headers: {
      Authorization: authorization
    }
  };
  const { ok, status, statusText } = await fetch__default["default"](
    `https://${host}/rest/git-lfs/admin/projects/${project}/repos/${repo}/enabled`,
    options
  );
  if (!ok)
    throw new Error(
      `Failed to enable LFS in the repository, ${status}: ${statusText}`
    );
};
function createPublishBitbucketAction(options) {
  const { integrations, config } = options;
  return pluginScaffolderNode.createTemplateAction({
    id: "publish:bitbucket",
    description: "Initializes a git repository of the content in the workspace, and publishes it to Bitbucket.",
    schema: {
      input: {
        type: "object",
        required: ["repoUrl"],
        properties: {
          repoUrl: {
            title: "Repository Location",
            type: "string"
          },
          description: {
            title: "Repository Description",
            type: "string"
          },
          repoVisibility: {
            title: "Repository Visibility",
            type: "string",
            enum: ["private", "public"]
          },
          defaultBranch: {
            title: "Default Branch",
            type: "string",
            description: `Sets the default branch on the repository. The default value is 'master'`
          },
          sourcePath: {
            title: "Source Path",
            description: "Path within the workspace that will be used as the repository root. If omitted, the entire workspace will be published as the repository.",
            type: "string"
          },
          enableLFS: {
            title: "Enable LFS?",
            description: "Enable LFS for the repository. Only available for hosted Bitbucket.",
            type: "boolean"
          },
          token: {
            title: "Authentication Token",
            type: "string",
            description: "The token to use for authorization to BitBucket"
          },
          gitCommitMessage: {
            title: "Git Commit Message",
            type: "string",
            description: `Sets the commit message on the repository. The default value is 'initial commit'`
          },
          gitAuthorName: {
            title: "Default Author Name",
            type: "string",
            description: `Sets the default author name for the commit. The default value is 'Scaffolder'`
          },
          gitAuthorEmail: {
            title: "Default Author Email",
            type: "string",
            description: `Sets the default author email for the commit.`
          }
        }
      },
      output: {
        type: "object",
        properties: {
          remoteUrl: {
            title: "A URL to the repository with the provider",
            type: "string"
          },
          repoContentsUrl: {
            title: "A URL to the root of the repository",
            type: "string"
          },
          commitHash: {
            title: "The git commit hash of the initial commit",
            type: "string"
          }
        }
      }
    },
    async handler(ctx) {
      var _a;
      ctx.logger.warn(
        `[Deprecated] Please migrate the use of action "publish:bitbucket" to "publish:bitbucketCloud" or "publish:bitbucketServer".`
      );
      const {
        repoUrl,
        description,
        defaultBranch = "master",
        repoVisibility = "private",
        enableLFS = false,
        gitCommitMessage = "initial commit",
        gitAuthorName,
        gitAuthorEmail
      } = ctx.input;
      const { workspace, project, repo, host } = parseRepoUrl(
        repoUrl,
        integrations
      );
      if (host === "bitbucket.org") {
        if (!workspace) {
          throw new errors.InputError(
            `Invalid URL provider was included in the repo URL to create ${ctx.input.repoUrl}, missing workspace`
          );
        }
      }
      if (!project) {
        throw new errors.InputError(
          `Invalid URL provider was included in the repo URL to create ${ctx.input.repoUrl}, missing project`
        );
      }
      const integrationConfig = integrations.bitbucket.byHost(host);
      if (!integrationConfig) {
        throw new errors.InputError(
          `No matching integration configuration for host ${host}, please check your integrations config`
        );
      }
      const authorization = getAuthorizationHeader$1(
        ctx.input.token ? {
          host: integrationConfig.config.host,
          apiBaseUrl: integrationConfig.config.apiBaseUrl,
          token: ctx.input.token
        } : integrationConfig.config
      );
      const apiBaseUrl = integrationConfig.config.apiBaseUrl;
      const createMethod = host === "bitbucket.org" ? createBitbucketCloudRepository : createBitbucketServerRepository;
      const { remoteUrl, repoContentsUrl } = await createMethod({
        authorization,
        workspace: workspace || "",
        project,
        repo,
        repoVisibility,
        mainBranch: defaultBranch,
        description,
        apiBaseUrl
      });
      const gitAuthorInfo = {
        name: gitAuthorName ? gitAuthorName : config.getOptionalString("scaffolder.defaultAuthor.name"),
        email: gitAuthorEmail ? gitAuthorEmail : config.getOptionalString("scaffolder.defaultAuthor.email")
      };
      let auth;
      if (ctx.input.token) {
        auth = {
          username: "x-token-auth",
          password: ctx.input.token
        };
      } else {
        auth = {
          username: integrationConfig.config.username ? integrationConfig.config.username : "x-token-auth",
          password: integrationConfig.config.appPassword ? integrationConfig.config.appPassword : (_a = integrationConfig.config.token) != null ? _a : ""
        };
      }
      const commitResult = await initRepoAndPush({
        dir: getRepoSourceDirectory(ctx.workspacePath, ctx.input.sourcePath),
        remoteUrl,
        auth,
        defaultBranch,
        logger: ctx.logger,
        commitMessage: gitCommitMessage ? gitCommitMessage : config.getOptionalString("scaffolder.defaultCommitMessage"),
        gitAuthorInfo
      });
      if (enableLFS && host !== "bitbucket.org") {
        await performEnableLFS$1({ authorization, host, project, repo });
      }
      ctx.output("commitHash", commitResult == null ? void 0 : commitResult.commitHash);
      ctx.output("remoteUrl", remoteUrl);
      ctx.output("repoContentsUrl", repoContentsUrl);
    }
  });
}

const createRepository$1 = async (opts) => {
  const {
    workspace,
    project,
    repo,
    description,
    repoVisibility,
    mainBranch,
    authorization,
    apiBaseUrl
  } = opts;
  const options = {
    method: "POST",
    body: JSON.stringify({
      scm: "git",
      description,
      is_private: repoVisibility === "private",
      project: { key: project }
    }),
    headers: {
      Authorization: authorization,
      "Content-Type": "application/json"
    }
  };
  let response;
  try {
    response = await fetch__default["default"](
      `${apiBaseUrl}/repositories/${workspace}/${repo}`,
      options
    );
  } catch (e) {
    throw new Error(`Unable to create repository, ${e}`);
  }
  if (response.status !== 200) {
    throw new Error(
      `Unable to create repository, ${response.status} ${response.statusText}, ${await response.text()}`
    );
  }
  const r = await response.json();
  let remoteUrl = "";
  for (const link of r.links.clone) {
    if (link.name === "https") {
      remoteUrl = link.href;
    }
  }
  const repoContentsUrl = `${r.links.html.href}/src/${mainBranch}`;
  return { remoteUrl, repoContentsUrl };
};
const getAuthorizationHeader = (config) => {
  if (config.username && config.appPassword) {
    const buffer = Buffer.from(
      `${config.username}:${config.appPassword}`,
      "utf8"
    );
    return `Basic ${buffer.toString("base64")}`;
  }
  if (config.token) {
    return `Bearer ${config.token}`;
  }
  throw new Error(
    `Authorization has not been provided for Bitbucket Cloud. Please add either username + appPassword to the Integrations config or a user login auth token`
  );
};
function createPublishBitbucketCloudAction(options) {
  const { integrations, config } = options;
  return pluginScaffolderNode.createTemplateAction({
    id: "publish:bitbucketCloud",
    description: "Initializes a git repository of the content in the workspace, and publishes it to Bitbucket Cloud.",
    schema: {
      input: {
        type: "object",
        required: ["repoUrl"],
        properties: {
          repoUrl: {
            title: "Repository Location",
            type: "string"
          },
          description: {
            title: "Repository Description",
            type: "string"
          },
          repoVisibility: {
            title: "Repository Visibility",
            type: "string",
            enum: ["private", "public"]
          },
          defaultBranch: {
            title: "Default Branch",
            type: "string",
            description: `Sets the default branch on the repository. The default value is 'master'`
          },
          sourcePath: {
            title: "Source Path",
            description: "Path within the workspace that will be used as the repository root. If omitted, the entire workspace will be published as the repository.",
            type: "string"
          },
          token: {
            title: "Authentication Token",
            type: "string",
            description: "The token to use for authorization to BitBucket Cloud"
          }
        }
      },
      output: {
        type: "object",
        properties: {
          remoteUrl: {
            title: "A URL to the repository with the provider",
            type: "string"
          },
          repoContentsUrl: {
            title: "A URL to the root of the repository",
            type: "string"
          },
          commitHash: {
            title: "The git commit hash of the initial commit",
            type: "string"
          }
        }
      }
    },
    async handler(ctx) {
      const {
        repoUrl,
        description,
        defaultBranch = "master",
        repoVisibility = "private"
      } = ctx.input;
      const { workspace, project, repo, host } = parseRepoUrl(
        repoUrl,
        integrations
      );
      if (!workspace) {
        throw new errors.InputError(
          `Invalid URL provider was included in the repo URL to create ${ctx.input.repoUrl}, missing workspace`
        );
      }
      if (!project) {
        throw new errors.InputError(
          `Invalid URL provider was included in the repo URL to create ${ctx.input.repoUrl}, missing project`
        );
      }
      const integrationConfig = integrations.bitbucketCloud.byHost(host);
      if (!integrationConfig) {
        throw new errors.InputError(
          `No matching integration configuration for host ${host}, please check your integrations config`
        );
      }
      const authorization = getAuthorizationHeader(
        ctx.input.token ? { token: ctx.input.token } : integrationConfig.config
      );
      const apiBaseUrl = integrationConfig.config.apiBaseUrl;
      const { remoteUrl, repoContentsUrl } = await createRepository$1({
        authorization,
        workspace: workspace || "",
        project,
        repo,
        repoVisibility,
        mainBranch: defaultBranch,
        description,
        apiBaseUrl
      });
      const gitAuthorInfo = {
        name: config.getOptionalString("scaffolder.defaultAuthor.name"),
        email: config.getOptionalString("scaffolder.defaultAuthor.email")
      };
      let auth;
      if (ctx.input.token) {
        auth = {
          username: "x-token-auth",
          password: ctx.input.token
        };
      } else {
        if (!integrationConfig.config.username || !integrationConfig.config.appPassword) {
          throw new Error(
            "Credentials for Bitbucket Cloud integration required for this action."
          );
        }
        auth = {
          username: integrationConfig.config.username,
          password: integrationConfig.config.appPassword
        };
      }
      const commitResult = await initRepoAndPush({
        dir: getRepoSourceDirectory(ctx.workspacePath, ctx.input.sourcePath),
        remoteUrl,
        auth,
        defaultBranch,
        logger: ctx.logger,
        commitMessage: config.getOptionalString(
          "scaffolder.defaultCommitMessage"
        ),
        gitAuthorInfo
      });
      ctx.output("commitHash", commitResult == null ? void 0 : commitResult.commitHash);
      ctx.output("remoteUrl", remoteUrl);
      ctx.output("repoContentsUrl", repoContentsUrl);
    }
  });
}

const createRepository = async (opts) => {
  const {
    project,
    repo,
    description,
    authorization,
    repoVisibility,
    defaultBranch,
    apiBaseUrl
  } = opts;
  let response;
  const options = {
    method: "POST",
    body: JSON.stringify({
      name: repo,
      description,
      defaultBranch,
      public: repoVisibility === "public"
    }),
    headers: {
      Authorization: authorization,
      "Content-Type": "application/json"
    }
  };
  try {
    response = await fetch__default["default"](`${apiBaseUrl}/projects/${project}/repos`, options);
  } catch (e) {
    throw new Error(`Unable to create repository, ${e}`);
  }
  if (response.status !== 201) {
    throw new Error(
      `Unable to create repository, ${response.status} ${response.statusText}, ${await response.text()}`
    );
  }
  const r = await response.json();
  let remoteUrl = "";
  for (const link of r.links.clone) {
    if (link.name === "http") {
      remoteUrl = link.href;
    }
  }
  const repoContentsUrl = `${r.links.self[0].href}`;
  return { remoteUrl, repoContentsUrl };
};
const performEnableLFS = async (opts) => {
  const { authorization, host, project, repo } = opts;
  const options = {
    method: "PUT",
    headers: {
      Authorization: authorization
    }
  };
  const { ok, status, statusText } = await fetch__default["default"](
    `https://${host}/rest/git-lfs/admin/projects/${project}/repos/${repo}/enabled`,
    options
  );
  if (!ok)
    throw new Error(
      `Failed to enable LFS in the repository, ${status}: ${statusText}`
    );
};
function createPublishBitbucketServerAction(options) {
  const { integrations, config } = options;
  return pluginScaffolderNode.createTemplateAction({
    id: "publish:bitbucketServer",
    description: "Initializes a git repository of the content in the workspace, and publishes it to Bitbucket Server.",
    schema: {
      input: {
        type: "object",
        required: ["repoUrl"],
        properties: {
          repoUrl: {
            title: "Repository Location",
            type: "string"
          },
          description: {
            title: "Repository Description",
            type: "string"
          },
          repoVisibility: {
            title: "Repository Visibility",
            type: "string",
            enum: ["private", "public"]
          },
          defaultBranch: {
            title: "Default Branch",
            type: "string",
            description: `Sets the default branch on the repository. The default value is 'master'`
          },
          sourcePath: {
            title: "Source Path",
            description: "Path within the workspace that will be used as the repository root. If omitted, the entire workspace will be published as the repository.",
            type: "string"
          },
          enableLFS: {
            title: "Enable LFS?",
            description: "Enable LFS for the repository.",
            type: "boolean"
          },
          token: {
            title: "Authentication Token",
            type: "string",
            description: "The token to use for authorization to BitBucket Server"
          },
          gitCommitMessage: {
            title: "Git Commit Message",
            type: "string",
            description: `Sets the commit message on the repository. The default value is 'initial commit'`
          },
          gitAuthorName: {
            title: "Author Name",
            type: "string",
            description: `Sets the author name for the commit. The default value is 'Scaffolder'`
          },
          gitAuthorEmail: {
            title: "Author Email",
            type: "string",
            description: `Sets the author email for the commit.`
          }
        }
      },
      output: {
        type: "object",
        properties: {
          remoteUrl: {
            title: "A URL to the repository with the provider",
            type: "string"
          },
          repoContentsUrl: {
            title: "A URL to the root of the repository",
            type: "string"
          },
          commitHash: {
            title: "The git commit hash of the initial commit",
            type: "string"
          }
        }
      }
    },
    async handler(ctx) {
      var _a;
      const {
        repoUrl,
        description,
        defaultBranch = "master",
        repoVisibility = "private",
        enableLFS = false,
        gitCommitMessage = "initial commit",
        gitAuthorName,
        gitAuthorEmail
      } = ctx.input;
      const { project, repo, host } = parseRepoUrl(repoUrl, integrations);
      if (!project) {
        throw new errors.InputError(
          `Invalid URL provider was included in the repo URL to create ${ctx.input.repoUrl}, missing project`
        );
      }
      const integrationConfig = integrations.bitbucketServer.byHost(host);
      if (!integrationConfig) {
        throw new errors.InputError(
          `No matching integration configuration for host ${host}, please check your integrations config`
        );
      }
      const token = (_a = ctx.input.token) != null ? _a : integrationConfig.config.token;
      const authConfig = {
        ...integrationConfig.config,
        ...{ token }
      };
      const reqOpts = integration.getBitbucketServerRequestOptions(authConfig);
      const authorization = reqOpts.headers.Authorization;
      if (!authorization) {
        throw new Error(
          `Authorization has not been provided for ${integrationConfig.config.host}. Please add either (a) a user login auth token, or (b) a token or (c) username + password to the integration config.`
        );
      }
      const apiBaseUrl = integrationConfig.config.apiBaseUrl;
      const { remoteUrl, repoContentsUrl } = await createRepository({
        authorization,
        project,
        repo,
        repoVisibility,
        defaultBranch,
        description,
        apiBaseUrl
      });
      const gitAuthorInfo = {
        name: gitAuthorName ? gitAuthorName : config.getOptionalString("scaffolder.defaultAuthor.name"),
        email: gitAuthorEmail ? gitAuthorEmail : config.getOptionalString("scaffolder.defaultAuthor.email")
      };
      const auth = authConfig.token ? {
        token
      } : {
        username: authConfig.username,
        password: authConfig.password
      };
      const commitResult = await initRepoAndPush({
        dir: getRepoSourceDirectory(ctx.workspacePath, ctx.input.sourcePath),
        remoteUrl,
        auth,
        defaultBranch,
        logger: ctx.logger,
        commitMessage: gitCommitMessage ? gitCommitMessage : config.getOptionalString("scaffolder.defaultCommitMessage"),
        gitAuthorInfo
      });
      if (enableLFS) {
        await performEnableLFS({ authorization, host, project, repo });
      }
      ctx.output("commitHash", commitResult == null ? void 0 : commitResult.commitHash);
      ctx.output("remoteUrl", remoteUrl);
      ctx.output("repoContentsUrl", repoContentsUrl);
    }
  });
}

const createGerritProject = async (config, options) => {
  const { projectName, parent, owner, description } = options;
  const fetchOptions = {
    method: "PUT",
    body: JSON.stringify({
      parent,
      description,
      owners: owner ? [owner] : [],
      create_empty_commit: false
    }),
    headers: {
      ...integration.getGerritRequestOptions(config).headers,
      "Content-Type": "application/json"
    }
  };
  const response = await fetch__default["default"](
    `${config.baseUrl}/a/projects/${encodeURIComponent(projectName)}`,
    fetchOptions
  );
  if (response.status !== 201) {
    throw new Error(
      `Unable to create repository, ${response.status} ${response.statusText}, ${await response.text()}`
    );
  }
};
const generateCommitMessage = (config, commitSubject) => {
  const changeId = crypto__default["default"].randomBytes(20).toString("hex");
  const msg = `${config.getOptionalString("scaffolder.defaultCommitMessage") || commitSubject}

Change-Id: I${changeId}`;
  return msg;
};
function createPublishGerritAction(options) {
  const { integrations, config } = options;
  return pluginScaffolderNode.createTemplateAction({
    id: "publish:gerrit",
    description: "Initializes a git repository of the content in the workspace, and publishes it to Gerrit.",
    schema: {
      input: {
        type: "object",
        required: ["repoUrl"],
        properties: {
          repoUrl: {
            title: "Repository Location",
            type: "string"
          },
          description: {
            title: "Repository Description",
            type: "string"
          },
          defaultBranch: {
            title: "Default Branch",
            type: "string",
            description: `Sets the default branch on the repository. The default value is 'master'`
          },
          gitCommitMessage: {
            title: "Git Commit Message",
            type: "string",
            description: `Sets the commit message on the repository. The default value is 'initial commit'`
          },
          gitAuthorName: {
            title: "Default Author Name",
            type: "string",
            description: `Sets the default author name for the commit. The default value is 'Scaffolder'`
          },
          gitAuthorEmail: {
            title: "Default Author Email",
            type: "string",
            description: `Sets the default author email for the commit.`
          },
          sourcePath: {
            title: "Source Path",
            type: "string",
            description: `Path within the workspace that will be used as the repository root. If omitted, the entire workspace will be published as the repository.`
          }
        }
      },
      output: {
        type: "object",
        properties: {
          remoteUrl: {
            title: "A URL to the repository with the provider",
            type: "string"
          },
          repoContentsUrl: {
            title: "A URL to the root of the repository",
            type: "string"
          },
          commitHash: {
            title: "The git commit hash of the initial commit",
            type: "string"
          }
        }
      }
    },
    async handler(ctx) {
      const {
        repoUrl,
        description,
        defaultBranch = "master",
        gitAuthorName,
        gitAuthorEmail,
        gitCommitMessage = "initial commit",
        sourcePath
      } = ctx.input;
      const { repo, host, owner, workspace } = parseRepoUrl(
        repoUrl,
        integrations
      );
      const integrationConfig = integrations.gerrit.byHost(host);
      if (!integrationConfig) {
        throw new errors.InputError(
          `No matching integration configuration for host ${host}, please check your integrations config`
        );
      }
      if (!workspace) {
        throw new errors.InputError(
          `Invalid URL provider was included in the repo URL to create ${ctx.input.repoUrl}, missing workspace`
        );
      }
      await createGerritProject(integrationConfig.config, {
        description,
        owner,
        projectName: repo,
        parent: workspace
      });
      const auth = {
        username: integrationConfig.config.username,
        password: integrationConfig.config.password
      };
      const gitAuthorInfo = {
        name: gitAuthorName ? gitAuthorName : config.getOptionalString("scaffolder.defaultAuthor.name"),
        email: gitAuthorEmail ? gitAuthorEmail : config.getOptionalString("scaffolder.defaultAuthor.email")
      };
      const remoteUrl = `${integrationConfig.config.cloneUrl}/a/${repo}`;
      const commitResult = await initRepoAndPush({
        dir: getRepoSourceDirectory(ctx.workspacePath, sourcePath),
        remoteUrl,
        auth,
        defaultBranch,
        logger: ctx.logger,
        commitMessage: generateCommitMessage(config, gitCommitMessage),
        gitAuthorInfo
      });
      const repoContentsUrl = `${integrationConfig.config.gitilesBaseUrl}/${repo}/+/refs/heads/${defaultBranch}`;
      ctx.output("remoteUrl", remoteUrl);
      ctx.output("commitHash", commitResult == null ? void 0 : commitResult.commitHash);
      ctx.output("repoContentsUrl", repoContentsUrl);
    }
  });
}

const generateGerritChangeId = () => {
  const changeId = crypto__default["default"].randomBytes(20).toString("hex");
  return `I${changeId}`;
};
function createPublishGerritReviewAction(options) {
  const { integrations, config } = options;
  return pluginScaffolderNode.createTemplateAction({
    id: "publish:gerrit:review",
    description: "Creates a new Gerrit review.",
    schema: {
      input: {
        type: "object",
        required: ["repoUrl", "gitCommitMessage"],
        properties: {
          repoUrl: {
            title: "Repository Location",
            type: "string"
          },
          branch: {
            title: "Repository branch",
            type: "string",
            description: "Branch of the repository the review will be created on"
          },
          sourcePath: {
            type: "string",
            title: "Working Subdirectory",
            description: "Subdirectory of working directory containing the repository"
          },
          gitCommitMessage: {
            title: "Git Commit Message",
            type: "string",
            description: `Sets the commit message on the repository.`
          },
          gitAuthorName: {
            title: "Default Author Name",
            type: "string",
            description: `Sets the default author name for the commit. The default value is 'Scaffolder'`
          },
          gitAuthorEmail: {
            title: "Default Author Email",
            type: "string",
            description: `Sets the default author email for the commit.`
          }
        }
      },
      output: {
        type: "object",
        properties: {
          reviewUrl: {
            title: "A URL to the review",
            type: "string"
          },
          repoContentsUrl: {
            title: "A URL to the root of the repository",
            type: "string"
          }
        }
      }
    },
    async handler(ctx) {
      var _a;
      const {
        repoUrl,
        branch = "master",
        sourcePath,
        gitAuthorName,
        gitAuthorEmail,
        gitCommitMessage
      } = ctx.input;
      const { host, repo } = parseRepoUrl(repoUrl, integrations);
      if (!gitCommitMessage) {
        throw new errors.InputError(`Missing gitCommitMessage input`);
      }
      const integrationConfig = integrations.gerrit.byHost(host);
      if (!integrationConfig) {
        throw new errors.InputError(
          `No matching integration configuration for host ${host}, please check your integrations config`
        );
      }
      const auth = {
        username: integrationConfig.config.username,
        password: integrationConfig.config.password
      };
      const gitAuthorInfo = {
        name: gitAuthorName ? gitAuthorName : config.getOptionalString("scaffolder.defaultAuthor.name"),
        email: gitAuthorEmail ? gitAuthorEmail : config.getOptionalString("scaffolder.defaultAuthor.email")
      };
      const changeId = generateGerritChangeId();
      const commitMessage = `${gitCommitMessage}

Change-Id: ${changeId}`;
      await commitAndPushRepo({
        dir: getRepoSourceDirectory(ctx.workspacePath, sourcePath),
        auth,
        logger: ctx.logger,
        commitMessage,
        gitAuthorInfo,
        branch,
        remoteRef: `refs/for/${branch}`
      });
      const repoContentsUrl = `${integrationConfig.config.gitilesBaseUrl}/${repo}/+/refs/heads/${branch}`;
      const reviewUrl = `${integrationConfig.config.baseUrl}/#/q/${changeId}`;
      (_a = ctx.logger) == null ? void 0 : _a.info(`Review available on ${reviewUrl}`);
      ctx.output("repoContentsUrl", repoContentsUrl);
      ctx.output("reviewUrl", reviewUrl);
    }
  });
}

function createPublishGithubAction(options) {
  const { integrations, config, githubCredentialsProvider } = options;
  return pluginScaffolderNode.createTemplateAction({
    id: "publish:github",
    description: "Initializes a git repository of contents in workspace and publishes it to GitHub.",
    schema: {
      input: {
        type: "object",
        required: ["repoUrl"],
        properties: {
          repoUrl: repoUrl,
          description: description,
          homepage: homepage,
          access: access,
          bypassPullRequestAllowances: bypassPullRequestAllowances,
          requiredApprovingReviewCount: requiredApprovingReviewCount,
          restrictions: restrictions,
          requireCodeOwnerReviews: requireCodeOwnerReviews,
          dismissStaleReviews: dismissStaleReviews,
          requiredStatusCheckContexts: requiredStatusCheckContexts,
          requireBranchesToBeUpToDate: requireBranchesToBeUpToDate,
          requiredConversationResolution: requiredConversationResolution,
          repoVisibility: repoVisibility,
          defaultBranch: defaultBranch,
          protectDefaultBranch: protectDefaultBranch,
          protectEnforceAdmins: protectEnforceAdmins,
          deleteBranchOnMerge: deleteBranchOnMerge,
          gitCommitMessage: gitCommitMessage,
          gitAuthorName: gitAuthorName,
          gitAuthorEmail: gitAuthorEmail,
          allowMergeCommit: allowMergeCommit,
          allowSquashMerge: allowSquashMerge,
          squashMergeCommitTitle: squashMergeCommitTitle,
          squashMergeCommitMessage: squashMergeCommitMessage,
          allowRebaseMerge: allowRebaseMerge,
          allowAutoMerge: allowAutoMerge,
          sourcePath: sourcePath,
          collaborators: collaborators,
          hasProjects: hasProjects,
          hasWiki: hasWiki,
          hasIssues: hasIssues,
          token: token,
          topics: topics,
          requiredCommitSigning: requiredCommitSigning
        }
      },
      output: {
        type: "object",
        properties: {
          remoteUrl: remoteUrl,
          repoContentsUrl: repoContentsUrl,
          commitHash: commitHash
        }
      }
    },
    async handler(ctx) {
      const {
        repoUrl,
        description,
        homepage,
        access,
        requireCodeOwnerReviews = false,
        dismissStaleReviews = false,
        bypassPullRequestAllowances,
        requiredApprovingReviewCount = 1,
        restrictions,
        requiredStatusCheckContexts = [],
        requireBranchesToBeUpToDate = true,
        requiredConversationResolution = false,
        repoVisibility = "private",
        defaultBranch = "master",
        protectDefaultBranch = true,
        protectEnforceAdmins = true,
        deleteBranchOnMerge = false,
        gitCommitMessage = "initial commit",
        gitAuthorName,
        gitAuthorEmail,
        allowMergeCommit = true,
        allowSquashMerge = true,
        squashMergeCommitTitle = "COMMIT_OR_PR_TITLE",
        squashMergeCommitMessage = "COMMIT_MESSAGES",
        allowRebaseMerge = true,
        allowAutoMerge = false,
        collaborators,
        hasProjects = void 0,
        hasWiki = void 0,
        hasIssues = void 0,
        topics,
        token: providedToken,
        requiredCommitSigning = false
      } = ctx.input;
      const octokitOptions = await getOctokitOptions({
        integrations,
        credentialsProvider: githubCredentialsProvider,
        token: providedToken,
        repoUrl
      });
      const client = new octokit.Octokit(octokitOptions);
      const { owner, repo } = parseRepoUrl(repoUrl, integrations);
      if (!owner) {
        throw new errors.InputError("Invalid repository owner provided in repoUrl");
      }
      const newRepo = await createGithubRepoWithCollaboratorsAndTopics(
        client,
        repo,
        owner,
        repoVisibility,
        description,
        homepage,
        deleteBranchOnMerge,
        allowMergeCommit,
        allowSquashMerge,
        squashMergeCommitTitle,
        squashMergeCommitMessage,
        allowRebaseMerge,
        allowAutoMerge,
        access,
        collaborators,
        hasProjects,
        hasWiki,
        hasIssues,
        topics,
        ctx.logger
      );
      const remoteUrl = newRepo.clone_url;
      const repoContentsUrl = `${newRepo.html_url}/blob/${defaultBranch}`;
      const commitResult = await initRepoPushAndProtect(
        remoteUrl,
        octokitOptions.auth,
        ctx.workspacePath,
        ctx.input.sourcePath,
        defaultBranch,
        protectDefaultBranch,
        protectEnforceAdmins,
        owner,
        client,
        repo,
        requireCodeOwnerReviews,
        bypassPullRequestAllowances,
        requiredApprovingReviewCount,
        restrictions,
        requiredStatusCheckContexts,
        requireBranchesToBeUpToDate,
        requiredConversationResolution,
        config,
        ctx.logger,
        gitCommitMessage,
        gitAuthorName,
        gitAuthorEmail,
        dismissStaleReviews,
        requiredCommitSigning
      );
      ctx.output("commitHash", commitResult == null ? void 0 : commitResult.commitHash);
      ctx.output("remoteUrl", remoteUrl);
      ctx.output("repoContentsUrl", repoContentsUrl);
    }
  });
}

const DEFAULT_GLOB_PATTERNS = ["./**", "!.git"];
const isExecutable = (fileMode) => {
  if (!fileMode) {
    return false;
  }
  const executeBitMask = 73;
  const res = fileMode & executeBitMask;
  return res > 0;
};
async function asyncFilter(array, callback) {
  const filterMap = await Promise.all(array.map(callback));
  return array.filter((_value, index) => filterMap[index]);
}
async function serializeDirectoryContents(sourcePath, options) {
  var _a;
  const paths = await globby__default["default"]((_a = options == null ? void 0 : options.globPatterns) != null ? _a : DEFAULT_GLOB_PATTERNS, {
    cwd: sourcePath,
    dot: true,
    gitignore: options == null ? void 0 : options.gitignore,
    followSymbolicLinks: false,
    // In order to pick up 'broken' symlinks, we oxymoronically request files AND folders yet we filter out folders
    // This is because broken symlinks aren't classed as files so we need to glob everything
    onlyFiles: false,
    objectMode: true,
    stats: true
  });
  const limiter = limiterFactory__default["default"](10);
  const valid = await asyncFilter(paths, async ({ dirent, path }) => {
    if (dirent.isDirectory())
      return false;
    if (!dirent.isSymbolicLink())
      return true;
    const safePath = backendCommon.resolveSafeChildPath(sourcePath, path);
    try {
      await fs$1.promises.stat(safePath);
      return false;
    } catch (e) {
      return errors.isError(e) && e.code === "ENOENT";
    }
  });
  return Promise.all(
    valid.map(async ({ dirent, path, stats }) => ({
      path,
      content: await limiter(async () => {
        const absFilePath = backendCommon.resolveSafeChildPath(sourcePath, path);
        if (dirent.isSymbolicLink()) {
          return fs$1.promises.readlink(absFilePath, "buffer");
        }
        return fs$1.promises.readFile(absFilePath);
      }),
      executable: isExecutable(stats == null ? void 0 : stats.mode),
      symlink: dirent.isSymbolicLink()
    }))
  );
}

async function deserializeDirectoryContents(targetPath, files) {
  for (const file of files) {
    const filePath = backendCommon.resolveSafeChildPath(targetPath, file.path);
    await fs__default["default"].ensureDir(path.dirname(filePath));
    await fs__default["default"].writeFile(filePath, file.content);
  }
}

class GithubResponseError extends errors.CustomErrorBase {
}
const defaultClientFactory = async ({
  integrations,
  githubCredentialsProvider,
  owner,
  repo,
  host = "github.com",
  token: providedToken
}) => {
  const [encodedHost, encodedOwner, encodedRepo] = [host, owner, repo].map(
    encodeURIComponent
  );
  const octokitOptions = await getOctokitOptions({
    integrations,
    credentialsProvider: githubCredentialsProvider,
    repoUrl: `${encodedHost}?owner=${encodedOwner}&repo=${encodedRepo}`,
    token: providedToken
  });
  const OctokitPR = octokit.Octokit.plugin(octokitPluginCreatePullRequest.createPullRequest);
  return new OctokitPR({
    ...octokitOptions,
    ...{ throttle: { enabled: false } }
  });
};
const createPublishGithubPullRequestAction = (options) => {
  const {
    integrations,
    githubCredentialsProvider,
    clientFactory = defaultClientFactory
  } = options;
  return pluginScaffolderNode.createTemplateAction({
    id: "publish:github:pull-request",
    schema: {
      input: {
        required: ["repoUrl", "title", "description", "branchName"],
        type: "object",
        properties: {
          repoUrl: {
            title: "Repository Location",
            description: `Accepts the format 'github.com?repo=reponame&owner=owner' where 'reponame' is the repository name and 'owner' is an organization or username`,
            type: "string"
          },
          branchName: {
            type: "string",
            title: "Branch Name",
            description: "The name for the branch"
          },
          title: {
            type: "string",
            title: "Pull Request Name",
            description: "The name for the pull request"
          },
          description: {
            type: "string",
            title: "Pull Request Description",
            description: "The description of the pull request"
          },
          draft: {
            type: "boolean",
            title: "Create as Draft",
            description: "Create a draft pull request"
          },
          sourcePath: {
            type: "string",
            title: "Working Subdirectory",
            description: "Subdirectory of working directory to copy changes from"
          },
          targetPath: {
            type: "string",
            title: "Repository Subdirectory",
            description: "Subdirectory of repository to apply changes to"
          },
          token: {
            title: "Authentication Token",
            type: "string",
            description: "The token to use for authorization to GitHub"
          },
          reviewers: {
            title: "Pull Request Reviewers",
            type: "array",
            items: {
              type: "string"
            },
            description: "The users that will be added as reviewers to the pull request"
          },
          teamReviewers: {
            title: "Pull Request Team Reviewers",
            type: "array",
            items: {
              type: "string"
            },
            description: "The teams that will be added as reviewers to the pull request"
          },
          commitMessage: {
            type: "string",
            title: "Commit Message",
            description: "The commit message for the pull request commit"
          }
        }
      },
      output: {
        required: ["remoteUrl"],
        type: "object",
        properties: {
          remoteUrl: {
            type: "string",
            title: "Pull Request URL",
            description: "Link to the pull request in Github"
          },
          pullRequestNumber: {
            type: "number",
            title: "Pull Request Number",
            description: "The pull request number"
          }
        }
      }
    },
    async handler(ctx) {
      const {
        repoUrl,
        branchName,
        title,
        description,
        draft,
        targetPath,
        sourcePath,
        token: providedToken,
        reviewers,
        teamReviewers,
        commitMessage
      } = ctx.input;
      const { owner, repo, host } = parseRepoUrl(repoUrl, integrations);
      if (!owner) {
        throw new errors.InputError(
          `No owner provided for host: ${host}, and repo ${repo}`
        );
      }
      const client = await clientFactory({
        integrations,
        githubCredentialsProvider,
        host,
        owner,
        repo,
        token: providedToken
      });
      const fileRoot = sourcePath ? backendCommon.resolveSafeChildPath(ctx.workspacePath, sourcePath) : ctx.workspacePath;
      const directoryContents = await serializeDirectoryContents(fileRoot, {
        gitignore: true
      });
      const determineFileMode = (file) => {
        if (file.symlink)
          return "120000";
        if (file.executable)
          return "100755";
        return "100644";
      };
      const determineFileEncoding = (file) => file.symlink ? "utf-8" : "base64";
      const files = Object.fromEntries(
        directoryContents.map((file) => [
          targetPath ? path__default["default"].posix.join(targetPath, file.path) : file.path,
          {
            // See the properties of tree items
            // in https://docs.github.com/en/rest/reference/git#trees
            mode: determineFileMode(file),
            // Always use base64 encoding where possible to avoid doubling a binary file in size
            // due to interpreting a binary file as utf-8 and sending github
            // the utf-8 encoded content. Symlinks are kept as utf-8 to avoid them
            // being formatted as a series of scrambled characters
            //
            // For example, the original gradle-wrapper.jar is 57.8k in https://github.com/kennethzfeng/pull-request-test/pull/5/files.
            // Its size could be doubled to 98.3K (See https://github.com/kennethzfeng/pull-request-test/pull/4/files)
            encoding: determineFileEncoding(file),
            content: file.content.toString(determineFileEncoding(file))
          }
        ])
      );
      try {
        const response = await client.createPullRequest({
          owner,
          repo,
          title,
          changes: [
            {
              files,
              commit: commitMessage != null ? commitMessage : title
            }
          ],
          body: description,
          head: branchName,
          draft
        });
        if (!response) {
          throw new GithubResponseError("null response from Github");
        }
        const pullRequestNumber = response.data.number;
        if (reviewers || teamReviewers) {
          const pullRequest = { owner, repo, number: pullRequestNumber };
          await requestReviewersOnPullRequest(
            pullRequest,
            reviewers,
            teamReviewers,
            client,
            ctx.logger
          );
        }
        ctx.output("remoteUrl", response.data.html_url);
        ctx.output("pullRequestNumber", pullRequestNumber);
      } catch (e) {
        throw new GithubResponseError("Pull request creation failed", e);
      }
    }
  });
  async function requestReviewersOnPullRequest(pr, reviewers, teamReviewers, client, logger) {
    var _a, _b, _c, _d;
    try {
      const result = await client.rest.pulls.requestReviewers({
        owner: pr.owner,
        repo: pr.repo,
        pull_number: pr.number,
        reviewers,
        team_reviewers: teamReviewers
      });
      const addedUsers = (_b = (_a = result.data.requested_reviewers) == null ? void 0 : _a.join(", ")) != null ? _b : "";
      const addedTeams = (_d = (_c = result.data.requested_teams) == null ? void 0 : _c.join(", ")) != null ? _d : "";
      logger.info(
        `Added users [${addedUsers}] and teams [${addedTeams}] as reviewers to Pull request ${pr.number}`
      );
    } catch (e) {
      logger.error(
        `Failure when adding reviewers to Pull request ${pr.number}`,
        e
      );
    }
  }
};

function createPublishGitlabAction(options) {
  const { integrations, config } = options;
  return pluginScaffolderNode.createTemplateAction({
    id: "publish:gitlab",
    description: "Initializes a git repository of the content in the workspace, and publishes it to GitLab.",
    schema: {
      input: {
        type: "object",
        required: ["repoUrl"],
        properties: {
          repoUrl: {
            title: "Repository Location",
            type: "string"
          },
          repoVisibility: {
            title: "Repository Visibility",
            type: "string",
            enum: ["private", "public", "internal"]
          },
          defaultBranch: {
            title: "Default Branch",
            type: "string",
            description: `Sets the default branch on the repository. The default value is 'master'`
          },
          gitCommitMessage: {
            title: "Git Commit Message",
            type: "string",
            description: `Sets the commit message on the repository. The default value is 'initial commit'`
          },
          gitAuthorName: {
            title: "Default Author Name",
            type: "string",
            description: `Sets the default author name for the commit. The default value is 'Scaffolder'`
          },
          gitAuthorEmail: {
            title: "Default Author Email",
            type: "string",
            description: `Sets the default author email for the commit.`
          },
          sourcePath: {
            title: "Source Path",
            description: "Path within the workspace that will be used as the repository root. If omitted, the entire workspace will be published as the repository.",
            type: "string"
          },
          token: {
            title: "Authentication Token",
            type: "string",
            description: "The token to use for authorization to GitLab"
          },
          setUserAsOwner: {
            title: "Set User As Owner",
            type: "boolean",
            description: "Set the token user as owner of the newly created repository. Requires a token authorized to do the edit in the integration configuration for the matching host"
          },
          topics: {
            title: "Topic labels",
            description: "Topic labels to apply on the repository.",
            type: "array",
            items: {
              type: "string"
            }
          }
        }
      },
      output: {
        type: "object",
        properties: {
          remoteUrl: {
            title: "A URL to the repository with the provider",
            type: "string"
          },
          repoContentsUrl: {
            title: "A URL to the root of the repository",
            type: "string"
          },
          projectId: {
            title: "The ID of the project",
            type: "string"
          },
          commitHash: {
            title: "The git commit hash of the initial commit",
            type: "string"
          }
        }
      }
    },
    async handler(ctx) {
      const {
        repoUrl,
        repoVisibility = "private",
        defaultBranch = "master",
        gitCommitMessage = "initial commit",
        gitAuthorName,
        gitAuthorEmail,
        setUserAsOwner = false,
        topics = []
      } = ctx.input;
      const { owner, repo, host } = parseRepoUrl(repoUrl, integrations);
      if (!owner) {
        throw new errors.InputError(
          `No owner provided for host: ${host}, and repo ${repo}`
        );
      }
      const integrationConfig = integrations.gitlab.byHost(host);
      if (!integrationConfig) {
        throw new errors.InputError(
          `No matching integration configuration for host ${host}, please check your integrations config`
        );
      }
      if (!integrationConfig.config.token && !ctx.input.token) {
        throw new errors.InputError(`No token available for host ${host}`);
      }
      const token = ctx.input.token || integrationConfig.config.token;
      const tokenType = ctx.input.token ? "oauthToken" : "token";
      const client = new node.Gitlab({
        host: integrationConfig.config.baseUrl,
        [tokenType]: token
      });
      let { id: targetNamespace } = await client.Namespaces.show(owner);
      const { id: userId } = await client.Users.current();
      if (!targetNamespace) {
        targetNamespace = userId;
      }
      const { id: projectId, http_url_to_repo } = await client.Projects.create({
        namespace_id: targetNamespace,
        name: repo,
        visibility: repoVisibility,
        ...topics.length ? { topics } : {}
      });
      if (setUserAsOwner && integrationConfig.config.token) {
        const adminClient = new node.Gitlab({
          host: integrationConfig.config.baseUrl,
          token: integrationConfig.config.token
        });
        await adminClient.ProjectMembers.add(projectId, userId, 50);
      }
      const remoteUrl = http_url_to_repo.replace(/\.git$/, "");
      const repoContentsUrl = `${remoteUrl}/-/blob/${defaultBranch}`;
      const gitAuthorInfo = {
        name: gitAuthorName ? gitAuthorName : config.getOptionalString("scaffolder.defaultAuthor.name"),
        email: gitAuthorEmail ? gitAuthorEmail : config.getOptionalString("scaffolder.defaultAuthor.email")
      };
      const commitResult = await initRepoAndPush({
        dir: getRepoSourceDirectory(ctx.workspacePath, ctx.input.sourcePath),
        remoteUrl: http_url_to_repo,
        defaultBranch,
        auth: {
          username: "oauth2",
          password: token
        },
        logger: ctx.logger,
        commitMessage: gitCommitMessage ? gitCommitMessage : config.getOptionalString("scaffolder.defaultCommitMessage"),
        gitAuthorInfo
      });
      ctx.output("commitHash", commitResult == null ? void 0 : commitResult.commitHash);
      ctx.output("remoteUrl", remoteUrl);
      ctx.output("repoContentsUrl", repoContentsUrl);
      ctx.output("projectId", projectId);
    }
  });
}

const createPublishGitlabMergeRequestAction = (options) => {
  const { integrations } = options;
  return pluginScaffolderNode.createTemplateAction({
    id: "publish:gitlab:merge-request",
    schema: {
      input: {
        required: ["repoUrl", "branchName"],
        type: "object",
        properties: {
          repoUrl: {
            type: "string",
            title: "Repository Location",
            description: `Accepts the format 'gitlab.com/group_name/project_name' where 'project_name' is the repository name and 'group_name' is a group or username`
          },
          /** @deprecated projectID is passed as query parameters in the repoUrl */
          projectid: {
            type: "string",
            title: "projectid",
            description: "Project ID/Name(slug) of the Gitlab Project"
          },
          title: {
            type: "string",
            title: "Merge Request Name",
            description: "The name for the merge request"
          },
          description: {
            type: "string",
            title: "Merge Request Description",
            description: "The description of the merge request"
          },
          branchName: {
            type: "string",
            title: "Destination Branch name",
            description: "The description of the merge request"
          },
          sourcePath: {
            type: "string",
            title: "Working Subdirectory",
            description: "Subdirectory of working directory to copy changes from"
          },
          targetPath: {
            type: "string",
            title: "Repository Subdirectory",
            description: "Subdirectory of repository to apply changes to"
          },
          token: {
            title: "Authentication Token",
            type: "string",
            description: "The token to use for authorization to GitLab"
          },
          commitAction: {
            title: "Commit action",
            type: "string",
            enum: ["create", "update", "delete"],
            description: "The action to be used for git commit. Defaults to create."
          },
          removeSourceBranch: {
            title: "Delete source branch",
            type: "boolean",
            description: "Option to delete source branch once the MR has been merged. Default: false"
          },
          assignee: {
            title: "Merge Request Assignee",
            type: "string",
            description: "User this merge request will be assigned to"
          }
        }
      },
      output: {
        type: "object",
        properties: {
          projectid: {
            title: "Gitlab Project id/Name(slug)",
            type: "string"
          },
          projectPath: {
            title: "Gitlab Project path",
            type: "string"
          },
          mergeRequestUrl: {
            title: "MergeRequest(MR) URL",
            type: "string",
            description: "Link to the merge request in GitLab"
          }
        }
      }
    },
    async handler(ctx) {
      const {
        assignee,
        branchName,
        description,
        repoUrl,
        removeSourceBranch,
        targetPath,
        sourcePath,
        title,
        token: providedToken
      } = ctx.input;
      const { host, owner, repo, project } = parseRepoUrl(
        repoUrl,
        integrations
      );
      const repoID = project ? project : `${owner}/${repo}`;
      const integrationConfig = integrations.gitlab.byHost(host);
      if (!integrationConfig) {
        throw new errors.InputError(
          `No matching integration configuration for host ${host}, please check your integrations config`
        );
      }
      if (!integrationConfig.config.token && !providedToken) {
        throw new errors.InputError(`No token available for host ${host}`);
      }
      const token = providedToken != null ? providedToken : integrationConfig.config.token;
      const tokenType = providedToken ? "oauthToken" : "token";
      const api = new node.Gitlab({
        host: integrationConfig.config.baseUrl,
        [tokenType]: token
      });
      let assigneeId = void 0;
      if (assignee !== void 0) {
        try {
          const assigneeUser = await api.Users.username(assignee);
          assigneeId = assigneeUser[0].id;
        } catch (e) {
          ctx.logger.warn(
            `Failed to find gitlab user id for ${assignee}: ${e}. Proceeding with MR creation without an assignee.`
          );
        }
      }
      let fileRoot;
      if (sourcePath) {
        fileRoot = backendCommon.resolveSafeChildPath(ctx.workspacePath, sourcePath);
      } else if (targetPath) {
        fileRoot = backendCommon.resolveSafeChildPath(ctx.workspacePath, targetPath);
      } else {
        fileRoot = ctx.workspacePath;
      }
      const fileContents = await serializeDirectoryContents(fileRoot, {
        gitignore: true
      });
      const actions = fileContents.map((file) => {
        var _a;
        return {
          action: (_a = ctx.input.commitAction) != null ? _a : "create",
          filePath: targetPath ? path__default["default"].posix.join(targetPath, file.path) : file.path,
          encoding: "base64",
          content: file.content.toString("base64"),
          execute_filemode: file.executable
        };
      });
      const projects = await api.Projects.show(repoID);
      const { default_branch: defaultBranch } = projects;
      try {
        await api.Branches.create(repoID, branchName, String(defaultBranch));
      } catch (e) {
        throw new errors.InputError(`The branch creation failed ${e}`);
      }
      try {
        await api.Commits.create(repoID, branchName, ctx.input.title, actions);
      } catch (e) {
        throw new errors.InputError(
          `Committing the changes to ${branchName} failed ${e}`
        );
      }
      try {
        const mergeRequestUrl = await api.MergeRequests.create(
          repoID,
          branchName,
          String(defaultBranch),
          title,
          {
            description,
            removeSourceBranch: removeSourceBranch ? removeSourceBranch : false,
            assigneeId
          }
        ).then((mergeRequest) => {
          return mergeRequest.web_url;
        });
        ctx.output("projectid", repoID);
        ctx.output("projectPath", repoID);
        ctx.output("mergeRequestUrl", mergeRequestUrl);
      } catch (e) {
        throw new errors.InputError(`Merge request creation failed${e}`);
      }
    }
  });
};

const createBuiltinActions = (options) => {
  const {
    reader,
    integrations,
    catalogClient,
    config,
    additionalTemplateFilters,
    additionalTemplateGlobals
  } = options;
  const githubCredentialsProvider = integration.DefaultGithubCredentialsProvider.fromIntegrations(integrations);
  const actions = [
    createFetchPlainAction({
      reader,
      integrations
    }),
    createFetchPlainFileAction({
      reader,
      integrations
    }),
    createFetchTemplateAction({
      integrations,
      reader,
      additionalTemplateFilters,
      additionalTemplateGlobals
    }),
    createPublishGerritAction({
      integrations,
      config
    }),
    createPublishGerritReviewAction({
      integrations,
      config
    }),
    createPublishGithubAction({
      integrations,
      config,
      githubCredentialsProvider
    }),
    createPublishGithubPullRequestAction({
      integrations,
      githubCredentialsProvider
    }),
    createPublishGitlabAction({
      integrations,
      config
    }),
    createPublishGitlabMergeRequestAction({
      integrations
    }),
    createPublishBitbucketAction({
      integrations,
      config
    }),
    createPublishBitbucketCloudAction({
      integrations,
      config
    }),
    createPublishBitbucketServerAction({
      integrations,
      config
    }),
    createPublishAzureAction({
      integrations,
      config
    }),
    createDebugLogAction(),
    createWaitAction(),
    createCatalogRegisterAction({ catalogClient, integrations }),
    createFetchCatalogEntityAction({ catalogClient }),
    createCatalogWriteAction(),
    createFilesystemDeleteAction(),
    createFilesystemRenameAction(),
    createGithubActionsDispatchAction({
      integrations,
      githubCredentialsProvider
    }),
    createGithubWebhookAction({
      integrations,
      githubCredentialsProvider
    }),
    createGithubIssuesLabelAction({
      integrations,
      githubCredentialsProvider
    }),
    createGithubRepoCreateAction({
      integrations,
      githubCredentialsProvider
    }),
    createGithubRepoPushAction({
      integrations,
      config,
      githubCredentialsProvider
    })
  ];
  return actions;
};

class TemplateActionRegistry {
  constructor() {
    this.actions = /* @__PURE__ */ new Map();
  }
  register(action) {
    if (this.actions.has(action.id)) {
      throw new errors.ConflictError(
        `Template action with ID '${action.id}' has already been registered`
      );
    }
    this.actions.set(action.id, action);
  }
  get(actionId) {
    const action = this.actions.get(actionId);
    if (!action) {
      throw new errors.NotFoundError(
        `Template action with ID '${actionId}' is not registered.`
      );
    }
    return action;
  }
  list() {
    return [...this.actions.values()];
  }
}

const migrationsDir = backendCommon.resolvePackagePath(
  "@backstage/plugin-scaffolder-backend",
  "migrations"
);
function isPluginDatabaseManager(opt) {
  return opt.getClient !== void 0;
}
const parseSqlDateToIsoString = (input) => {
  if (typeof input === "string") {
    return luxon.DateTime.fromSQL(input, { zone: "UTC" }).toISO();
  }
  return input;
};
class DatabaseTaskStore {
  static async create(options) {
    const { database } = options;
    const client = await this.getClient(database);
    await this.runMigrations(database, client);
    return new DatabaseTaskStore(client);
  }
  static async getClient(database) {
    if (isPluginDatabaseManager(database)) {
      return database.getClient();
    }
    return database;
  }
  static async runMigrations(database, client) {
    var _a;
    if (!isPluginDatabaseManager(database)) {
      await client.migrate.latest({
        directory: migrationsDir
      });
      return;
    }
    if (!((_a = database.migrations) == null ? void 0 : _a.skip)) {
      await client.migrate.latest({
        directory: migrationsDir
      });
    }
  }
  constructor(client) {
    this.db = client;
  }
  async list(options) {
    const queryBuilder = this.db("tasks");
    if (options.createdBy) {
      queryBuilder.where({
        created_by: options.createdBy
      });
    }
    const results = await queryBuilder.orderBy("created_at", "desc").select();
    const tasks = results.map((result) => {
      var _a;
      return {
        id: result.id,
        spec: JSON.parse(result.spec),
        status: result.status,
        createdBy: (_a = result.created_by) != null ? _a : void 0,
        lastHeartbeatAt: parseSqlDateToIsoString(result.last_heartbeat_at),
        createdAt: parseSqlDateToIsoString(result.created_at)
      };
    });
    return { tasks };
  }
  async getTask(taskId) {
    var _a;
    const [result] = await this.db("tasks").where({ id: taskId }).select();
    if (!result) {
      throw new errors.NotFoundError(`No task with id '${taskId}' found`);
    }
    try {
      const spec = JSON.parse(result.spec);
      const secrets = result.secrets ? JSON.parse(result.secrets) : void 0;
      return {
        id: result.id,
        spec,
        status: result.status,
        lastHeartbeatAt: parseSqlDateToIsoString(result.last_heartbeat_at),
        createdAt: parseSqlDateToIsoString(result.created_at),
        createdBy: (_a = result.created_by) != null ? _a : void 0,
        secrets
      };
    } catch (error) {
      throw new Error(`Failed to parse spec of task '${taskId}', ${error}`);
    }
  }
  async createTask(options) {
    var _a;
    const taskId = uuid.v4();
    await this.db("tasks").insert({
      id: taskId,
      spec: JSON.stringify(options.spec),
      secrets: options.secrets ? JSON.stringify(options.secrets) : void 0,
      created_by: (_a = options.createdBy) != null ? _a : null,
      status: "open"
    });
    return { taskId };
  }
  async claimTask() {
    return this.db.transaction(async (tx) => {
      var _a;
      const [task] = await tx("tasks").where({
        status: "open"
      }).limit(1).select();
      if (!task) {
        return void 0;
      }
      const updateCount = await tx("tasks").where({ id: task.id, status: "open" }).update({
        status: "processing",
        last_heartbeat_at: this.db.fn.now(),
        // remove the secrets when moving to processing state.
        secrets: null
      });
      if (updateCount < 1) {
        return void 0;
      }
      try {
        const spec = JSON.parse(task.spec);
        const secrets = task.secrets ? JSON.parse(task.secrets) : void 0;
        return {
          id: task.id,
          spec,
          status: "processing",
          lastHeartbeatAt: task.last_heartbeat_at,
          createdAt: task.created_at,
          createdBy: (_a = task.created_by) != null ? _a : void 0,
          secrets
        };
      } catch (error) {
        throw new Error(`Failed to parse spec of task '${task.id}', ${error}`);
      }
    });
  }
  async heartbeatTask(taskId) {
    const updateCount = await this.db("tasks").where({ id: taskId, status: "processing" }).update({
      last_heartbeat_at: this.db.fn.now()
    });
    if (updateCount === 0) {
      throw new errors.ConflictError(`No running task with taskId ${taskId} found`);
    }
  }
  async listStaleTasks(options) {
    const { timeoutS } = options;
    const rawRows = await this.db("tasks").where("status", "processing").andWhere(
      "last_heartbeat_at",
      "<=",
      this.db.client.config.client.includes("sqlite3") ? this.db.raw(`datetime('now', ?)`, [`-${timeoutS} seconds`]) : this.db.raw(`? - interval '${timeoutS} seconds'`, [
        this.db.fn.now()
      ])
    );
    const tasks = rawRows.map((row) => ({
      taskId: row.id
    }));
    return { tasks };
  }
  async completeTask(options) {
    const { taskId, status, eventBody } = options;
    let oldStatus;
    if (["failed", "completed", "cancelled"].includes(status)) {
      oldStatus = "processing";
    } else {
      throw new Error(
        `Invalid status update of run '${taskId}' to status '${status}'`
      );
    }
    await this.db.transaction(async (tx) => {
      const [task] = await tx("tasks").where({
        id: taskId
      }).limit(1).select();
      const updateTask = async (criteria) => {
        const updateCount = await tx("tasks").where(criteria).update({
          status
        });
        if (updateCount !== 1) {
          throw new errors.ConflictError(
            `Failed to update status to '${status}' for taskId ${taskId}`
          );
        }
        await tx("task_events").insert({
          task_id: taskId,
          event_type: "completion",
          body: JSON.stringify(eventBody)
        });
      };
      if (status === "cancelled") {
        await updateTask({
          id: taskId
        });
        return;
      }
      if (task.status === "cancelled") {
        return;
      }
      if (!task) {
        throw new Error(`No task with taskId ${taskId} found`);
      }
      if (task.status !== oldStatus) {
        throw new errors.ConflictError(
          `Refusing to update status of run '${taskId}' to status '${status}' as it is currently '${task.status}', expected '${oldStatus}'`
        );
      }
      await updateTask({
        id: taskId,
        status: oldStatus
      });
    });
  }
  async emitLogEvent(options) {
    const { taskId, body } = options;
    const serializedBody = JSON.stringify(body);
    await this.db("task_events").insert({
      task_id: taskId,
      event_type: "log",
      body: serializedBody
    });
  }
  async listEvents(options) {
    const { taskId, after } = options;
    const rawEvents = await this.db("task_events").where({
      task_id: taskId
    }).andWhere((builder) => {
      if (typeof after === "number") {
        builder.where("id", ">", after).orWhere("event_type", "completion");
      }
    }).orderBy("id").select();
    const events = rawEvents.map((event) => {
      try {
        const body = JSON.parse(event.body);
        return {
          id: Number(event.id),
          taskId,
          body,
          type: event.event_type,
          createdAt: parseSqlDateToIsoString(event.created_at)
        };
      } catch (error) {
        throw new Error(
          `Failed to parse event body from event taskId=${taskId} id=${event.id}, ${error}`
        );
      }
    });
    return { events };
  }
  async shutdownTask(options) {
    const { taskId } = options;
    const message = `This task was marked as stale as it exceeded its timeout`;
    const statusStepEvents = (await this.listEvents({ taskId })).events.filter(
      ({ body }) => body == null ? void 0 : body.stepId
    );
    const completedSteps = statusStepEvents.filter(
      ({ body: { status } }) => status === "failed" || status === "completed"
    ).map((step) => step.body.stepId);
    const hungProcessingSteps = statusStepEvents.filter(({ body: { status } }) => status === "processing").map((event) => event.body.stepId).filter((step) => !completedSteps.includes(step));
    for (const step of hungProcessingSteps) {
      await this.emitLogEvent({
        taskId,
        body: {
          message,
          stepId: step,
          status: "failed"
        }
      });
    }
    await this.completeTask({
      taskId,
      status: "failed",
      eventBody: {
        message
      }
    });
  }
  async cancelTask(options) {
    const { taskId, body } = options;
    const serializedBody = JSON.stringify(body);
    await this.db("task_events").insert({
      task_id: taskId,
      event_type: "cancelled",
      body: serializedBody
    });
  }
}

class TaskManager {
  // Runs heartbeat internally
  constructor(task, storage, signal, logger) {
    this.task = task;
    this.storage = storage;
    this.signal = signal;
    this.logger = logger;
    this.isDone = false;
  }
  static create(task, storage, abortSignal, logger) {
    const agent = new TaskManager(task, storage, abortSignal, logger);
    agent.startTimeout();
    return agent;
  }
  get spec() {
    return this.task.spec;
  }
  get cancelSignal() {
    return this.signal;
  }
  get secrets() {
    return this.task.secrets;
  }
  get createdBy() {
    return this.task.createdBy;
  }
  async getWorkspaceName() {
    return this.task.taskId;
  }
  get done() {
    return this.isDone;
  }
  async emitLog(message, logMetadata) {
    await this.storage.emitLogEvent({
      taskId: this.task.taskId,
      body: { message, ...logMetadata }
    });
  }
  async complete(result, metadata) {
    await this.storage.completeTask({
      taskId: this.task.taskId,
      status: result === "failed" ? "failed" : "completed",
      eventBody: {
        message: `Run completed with status: ${result}`,
        ...metadata
      }
    });
    this.isDone = true;
    if (this.heartbeatTimeoutId) {
      clearTimeout(this.heartbeatTimeoutId);
    }
  }
  startTimeout() {
    this.heartbeatTimeoutId = setTimeout(async () => {
      try {
        await this.storage.heartbeatTask(this.task.taskId);
        this.startTimeout();
      } catch (error) {
        this.isDone = true;
        this.logger.error(
          `Heartbeat for task ${this.task.taskId} failed`,
          error
        );
      }
    }, 1e3);
  }
}
function defer() {
  let resolve = () => {
  };
  const promise = new Promise((_resolve) => {
    resolve = _resolve;
  });
  return { promise, resolve };
}
class StorageTaskBroker {
  constructor(storage, logger) {
    this.storage = storage;
    this.logger = logger;
    this.deferredDispatch = defer();
  }
  async list(options) {
    if (!this.storage.list) {
      throw new Error(
        "TaskStore does not implement the list method. Please implement the list method to be able to list tasks"
      );
    }
    return await this.storage.list({ createdBy: options == null ? void 0 : options.createdBy });
  }
  async registerCancellable(taskId, abortController) {
    let shouldUnsubscribe = false;
    const subscription = this.event$({ taskId, after: void 0 }).subscribe({
      error: (_) => {
        subscription.unsubscribe();
      },
      next: ({ events }) => {
        for (const event of events) {
          if (event.type === "cancelled") {
            abortController.abort();
            shouldUnsubscribe = true;
          }
          if (event.type === "completion") {
            shouldUnsubscribe = true;
          }
        }
        if (shouldUnsubscribe) {
          subscription.unsubscribe();
        }
      }
    });
  }
  /**
   * {@inheritdoc TaskBroker.claim}
   */
  async claim() {
    for (; ; ) {
      const pendingTask = await this.storage.claimTask();
      if (pendingTask) {
        const abortController = new AbortController();
        await this.registerCancellable(pendingTask.id, abortController);
        return TaskManager.create(
          {
            taskId: pendingTask.id,
            spec: pendingTask.spec,
            secrets: pendingTask.secrets,
            createdBy: pendingTask.createdBy
          },
          this.storage,
          abortController.signal,
          this.logger
        );
      }
      await this.waitForDispatch();
    }
  }
  /**
   * {@inheritdoc TaskBroker.dispatch}
   */
  async dispatch(options) {
    const taskRow = await this.storage.createTask(options);
    this.signalDispatch();
    return {
      taskId: taskRow.taskId
    };
  }
  /**
   * {@inheritdoc TaskBroker.get}
   */
  async get(taskId) {
    return this.storage.getTask(taskId);
  }
  /**
   * {@inheritdoc TaskBroker.event$}
   */
  event$(options) {
    return new ObservableImpl__default["default"]((observer) => {
      const { taskId } = options;
      let after = options.after;
      let cancelled = false;
      (async () => {
        while (!cancelled) {
          const result = await this.storage.listEvents({ taskId, after });
          const { events } = result;
          if (events.length) {
            after = events[events.length - 1].id;
            observer.next(result);
          }
          await new Promise((resolve) => setTimeout(resolve, 1e3));
        }
      })();
      return () => {
        cancelled = true;
      };
    });
  }
  /**
   * {@inheritdoc TaskBroker.vacuumTasks}
   */
  async vacuumTasks(options) {
    const { tasks } = await this.storage.listStaleTasks(options);
    await Promise.all(
      tasks.map(async (task) => {
        try {
          await this.storage.completeTask({
            taskId: task.taskId,
            status: "failed",
            eventBody: {
              message: "The task was cancelled because the task worker lost connection to the task broker"
            }
          });
        } catch (error) {
          this.logger.warn(`Failed to cancel task '${task.taskId}', ${error}`);
        }
      })
    );
  }
  waitForDispatch() {
    return this.deferredDispatch.promise;
  }
  signalDispatch() {
    this.deferredDispatch.resolve();
    this.deferredDispatch = defer();
  }
  async cancel(taskId) {
    var _a, _b;
    const { events } = await this.storage.listEvents({ taskId });
    const currentStepId = events.length > 0 ? events.filter(({ body }) => body == null ? void 0 : body.stepId).reduce((prev, curr) => prev.id > curr.id ? prev : curr).body.stepId : 0;
    await ((_b = (_a = this.storage).cancelTask) == null ? void 0 : _b.call(_a, {
      taskId,
      body: {
        message: `Step ${currentStepId} has been cancelled.`,
        stepId: currentStepId,
        status: "cancelled"
      }
    }));
  }
}

function isTruthy(value) {
  return lodash.isArray(value) ? value.length > 0 : !!value;
}
function generateExampleOutput(schema) {
  var _a, _b;
  const { examples } = schema;
  if (examples && Array.isArray(examples)) {
    return examples[0];
  }
  if (schema.type === "object") {
    return Object.fromEntries(
      Object.entries((_a = schema.properties) != null ? _a : {}).map(([key, value]) => [
        key,
        generateExampleOutput(value)
      ])
    );
  } else if (schema.type === "array") {
    const [firstSchema] = (_b = [schema.items]) == null ? void 0 : _b.flat();
    if (firstSchema) {
      return [generateExampleOutput(firstSchema)];
    }
    return [];
  } else if (schema.type === "string") {
    return "<example>";
  } else if (schema.type === "number") {
    return 0;
  } else if (schema.type === "boolean") {
    return false;
  }
  return "<unknown>";
}

function createCounterMetric(config) {
  let metric = promClient.register.getSingleMetric(config.name);
  if (!metric) {
    metric = new promClient.Counter(config);
    promClient.register.registerMetric(metric);
  }
  return metric;
}
function createHistogramMetric(config) {
  let metric = promClient.register.getSingleMetric(config.name);
  if (!metric) {
    metric = new promClient.Histogram(config);
    promClient.register.registerMetric(metric);
  }
  return metric;
}

const createTemplatePermissionRule = pluginPermissionNode.makeCreatePermissionRule();
const hasTag = createTemplatePermissionRule({
  name: "HAS_TAG",
  resourceType: alpha.RESOURCE_TYPE_SCAFFOLDER_TEMPLATE,
  description: `Match parameters or steps with the given tag`,
  paramsSchema: zod.z.object({
    tag: zod.z.string().describe("Name of the tag to match on")
  }),
  apply: (resource, { tag }) => {
    var _a, _b, _c;
    return (_c = (_b = (_a = resource["backstage:permissions"]) == null ? void 0 : _a.tags) == null ? void 0 : _b.includes(tag)) != null ? _c : false;
  },
  toQuery: () => ({})
});
const createActionPermissionRule = pluginPermissionNode.makeCreatePermissionRule();
const hasActionId = createActionPermissionRule({
  name: "HAS_ACTION_ID",
  resourceType: alpha.RESOURCE_TYPE_SCAFFOLDER_ACTION,
  description: `Match actions with the given actionId`,
  paramsSchema: zod.z.object({
    actionId: zod.z.string().describe("Name of the actionId to match on")
  }),
  apply: (resource, { actionId }) => {
    return resource.action === actionId;
  },
  toQuery: () => ({})
});
buildHasProperty({
  name: "HAS_PROPERTY",
  valueSchema: zod.z.union([zod.z.string(), zod.z.number(), zod.z.boolean(), zod.z.null()]),
  validateProperty: false
});
const hasBooleanProperty = buildHasProperty({
  name: "HAS_BOOLEAN_PROPERTY",
  valueSchema: zod.z.boolean()
});
const hasNumberProperty = buildHasProperty({
  name: "HAS_NUMBER_PROPERTY",
  valueSchema: zod.z.number()
});
const hasStringProperty = buildHasProperty({
  name: "HAS_STRING_PROPERTY",
  valueSchema: zod.z.string()
});
function buildHasProperty({
  name,
  valueSchema,
  validateProperty = true
}) {
  return createActionPermissionRule({
    name,
    description: `Allow actions with the specified property`,
    resourceType: alpha.RESOURCE_TYPE_SCAFFOLDER_ACTION,
    paramsSchema: zod.z.object({
      key: zod.z.string().describe(`Property within the action parameters to match on`),
      value: valueSchema.describe(`Value of the given property to match on`)
    }),
    apply: (resource, { key, value }) => {
      const foundValue = lodash.get(resource.input, key);
      if (validateProperty && !valueSchema.safeParse(foundValue).success) {
        return false;
      }
      if (value !== void 0) {
        if (valueSchema.safeParse(value).success) {
          return value === foundValue;
        }
        return false;
      }
      return foundValue !== void 0;
    },
    toQuery: () => ({})
  });
}
const scaffolderTemplateRules = { hasTag };
const scaffolderActionRules = {
  hasActionId,
  hasBooleanProperty,
  hasNumberProperty,
  hasStringProperty
};

const isValidTaskSpec = (taskSpec) => {
  return taskSpec.apiVersion === "scaffolder.backstage.io/v1beta3";
};
const createStepLogger = ({
  task,
  step
}) => {
  const metadata = { stepId: step.id };
  const taskLogger = winston__namespace.createLogger({
    level: process.env.LOG_LEVEL || "info",
    format: winston__namespace.format.combine(
      winston__namespace.format.colorize(),
      winston__namespace.format.simple()
    ),
    defaultMeta: {}
  });
  const streamLogger = new stream.PassThrough();
  streamLogger.on("data", async (data) => {
    const message = data.toString().trim();
    if ((message == null ? void 0 : message.length) > 1) {
      await task.emitLog(message, metadata);
    }
  });
  taskLogger.add(new winston__namespace.transports.Stream({ stream: streamLogger }));
  return { taskLogger, streamLogger };
};
const isActionAuthorized = pluginPermissionNode.createConditionAuthorizer(
  Object.values(scaffolderActionRules)
);
class NunjucksWorkflowRunner {
  constructor(options) {
    this.options = options;
    this.tracker = scaffoldingTracker();
    this.defaultTemplateFilters = createDefaultFilters({
      integrations: this.options.integrations
    });
  }
  isSingleTemplateString(input) {
    var _a, _b;
    const { parser, nodes } = nunjucks__default["default"];
    const parsed = parser.parse(
      input,
      {},
      {
        autoescape: false,
        tags: {
          variableStart: "${{",
          variableEnd: "}}"
        }
      }
    );
    return parsed.children.length === 1 && !(((_b = (_a = parsed.children[0]) == null ? void 0 : _a.children) == null ? void 0 : _b[0]) instanceof nodes.TemplateData);
  }
  render(input, context, renderTemplate) {
    return JSON.parse(JSON.stringify(input), (_key, value) => {
      try {
        if (typeof value === "string") {
          try {
            if (this.isSingleTemplateString(value)) {
              const wrappedDumped = value.replace(
                /\${{(.+)}}/g,
                "${{ ( $1 ) | dump }}"
              );
              const templated2 = renderTemplate(wrappedDumped, context);
              if (templated2 === "") {
                return void 0;
              }
              return JSON.parse(templated2);
            }
          } catch (ex) {
            this.options.logger.error(
              `Failed to parse template string: ${value} with error ${ex.message}`
            );
          }
          const templated = renderTemplate(value, context);
          if (templated === "") {
            return void 0;
          }
          return templated;
        }
      } catch {
        return value;
      }
      return value;
    });
  }
  async executeStep(task, step, context, renderTemplate, taskTrack, workspacePath, decision) {
    var _a, _b, _c, _d, _e, _f, _g;
    const stepTrack = await this.tracker.stepStart(task, step);
    if (task.cancelSignal.aborted) {
      throw new Error(`Step ${step.name} has been cancelled.`);
    }
    try {
      if (step.if) {
        const ifResult = await this.render(step.if, context, renderTemplate);
        if (!isTruthy(ifResult)) {
          await stepTrack.skipFalsy();
          return;
        }
      }
      const action = this.options.actionRegistry.get(step.action);
      const { taskLogger, streamLogger } = createStepLogger({ task, step });
      if (task.isDryRun) {
        const redactedSecrets = Object.fromEntries(
          Object.entries((_a = task.secrets) != null ? _a : {}).map((secret) => [
            secret[0],
            "[REDACTED]"
          ])
        );
        const debugInput = (_b = step.input && this.render(
          step.input,
          {
            ...context,
            secrets: redactedSecrets
          },
          renderTemplate
        )) != null ? _b : {};
        taskLogger.info(
          `Running ${action.id} in dry-run mode with inputs (secrets redacted): ${JSON.stringify(
            debugInput,
            void 0,
            2
          )}`
        );
        if (!action.supportsDryRun) {
          await taskTrack.skipDryRun(step, action);
          const outputSchema = (_c = action.schema) == null ? void 0 : _c.output;
          if (outputSchema) {
            context.steps[step.id] = {
              output: generateExampleOutput(outputSchema)
            };
          } else {
            context.steps[step.id] = { output: {} };
          }
          return;
        }
      }
      const input = (_e = step.input && this.render(
        step.input,
        { ...context, secrets: (_d = task.secrets) != null ? _d : {} },
        renderTemplate
      )) != null ? _e : {};
      if ((_f = action.schema) == null ? void 0 : _f.input) {
        const validateResult = jsonschema.validate(input, action.schema.input);
        if (!validateResult.valid) {
          const errors$1 = validateResult.errors.join(", ");
          throw new errors.InputError(
            `Invalid input passed to action ${action.id}, ${errors$1}`
          );
        }
      }
      if (!isActionAuthorized(decision, { action: action.id, input })) {
        throw new errors.NotAllowedError(
          `Unauthorized action: ${action.id}. The action is not allowed. Input: ${JSON.stringify(
            input,
            null,
            2
          )}`
        );
      }
      const tmpDirs = new Array();
      const stepOutput = {};
      await action.handler({
        input,
        secrets: (_g = task.secrets) != null ? _g : {},
        logger: taskLogger,
        logStream: streamLogger,
        workspacePath,
        createTemporaryDirectory: async () => {
          const tmpDir = await fs__default["default"].mkdtemp(`${workspacePath}_step-${step.id}-`);
          tmpDirs.push(tmpDir);
          return tmpDir;
        },
        output(name, value) {
          stepOutput[name] = value;
        },
        templateInfo: task.spec.templateInfo,
        user: task.spec.user,
        isDryRun: task.isDryRun,
        signal: task.cancelSignal
      });
      for (const tmpDir of tmpDirs) {
        await fs__default["default"].remove(tmpDir);
      }
      context.steps[step.id] = { output: stepOutput };
      if (task.cancelSignal.aborted) {
        throw new Error(`Step ${step.name} has been cancelled.`);
      }
      await stepTrack.markSuccessful();
    } catch (err) {
      await taskTrack.markFailed(step, err);
      await stepTrack.markFailed();
      throw err;
    }
  }
  async execute(task) {
    var _a;
    if (!isValidTaskSpec(task.spec)) {
      throw new errors.InputError(
        "Wrong template version executed with the workflow engine"
      );
    }
    const workspacePath = path__default["default"].join(
      this.options.workingDirectory,
      await task.getWorkspaceName()
    );
    const { additionalTemplateFilters, additionalTemplateGlobals } = this.options;
    const renderTemplate = await SecureTemplater.loadRenderer({
      templateFilters: {
        ...this.defaultTemplateFilters,
        ...additionalTemplateFilters
      },
      templateGlobals: additionalTemplateGlobals
    });
    try {
      const taskTrack = await this.tracker.taskStart(task);
      await fs__default["default"].ensureDir(workspacePath);
      const context = {
        parameters: task.spec.parameters,
        steps: {},
        user: task.spec.user
      };
      const [decision] = this.options.permissions && task.spec.steps.length ? await this.options.permissions.authorizeConditional(
        [{ permission: alpha.actionExecutePermission }],
        { token: (_a = task.secrets) == null ? void 0 : _a.backstageToken }
      ) : [{ result: pluginPermissionCommon.AuthorizeResult.ALLOW }];
      for (const step of task.spec.steps) {
        await this.executeStep(
          task,
          step,
          context,
          renderTemplate,
          taskTrack,
          workspacePath,
          decision
        );
      }
      const output = this.render(task.spec.output, context, renderTemplate);
      await taskTrack.markSuccessful();
      return { output };
    } finally {
      if (workspacePath) {
        await fs__default["default"].remove(workspacePath);
      }
    }
  }
}
function scaffoldingTracker() {
  const taskCount = createCounterMetric({
    name: "scaffolder_task_count",
    help: "Count of task runs",
    labelNames: ["template", "user", "result"]
  });
  const taskDuration = createHistogramMetric({
    name: "scaffolder_task_duration",
    help: "Duration of a task run",
    labelNames: ["template", "result"]
  });
  const stepCount = createCounterMetric({
    name: "scaffolder_step_count",
    help: "Count of step runs",
    labelNames: ["template", "step", "result"]
  });
  const stepDuration = createHistogramMetric({
    name: "scaffolder_step_duration",
    help: "Duration of a step runs",
    labelNames: ["template", "step", "result"]
  });
  async function taskStart(task) {
    var _a, _b;
    await task.emitLog(`Starting up task with ${task.spec.steps.length} steps`);
    const template = ((_a = task.spec.templateInfo) == null ? void 0 : _a.entityRef) || "";
    const user = ((_b = task.spec.user) == null ? void 0 : _b.ref) || "";
    const taskTimer = taskDuration.startTimer({
      template
    });
    async function skipDryRun(step, action) {
      task.emitLog(`Skipping because ${action.id} does not support dry-run`, {
        stepId: step.id,
        status: "skipped"
      });
    }
    async function markSuccessful() {
      taskCount.inc({
        template,
        user,
        result: "ok"
      });
      taskTimer({ result: "ok" });
    }
    async function markFailed(step, err) {
      await task.emitLog(String(err.stack), {
        stepId: step.id,
        status: "failed"
      });
      taskCount.inc({
        template,
        user,
        result: "failed"
      });
      taskTimer({ result: "failed" });
    }
    async function markCancelled(step) {
      await task.emitLog(`Step ${step.id} has been cancelled.`, {
        stepId: step.id,
        status: "cancelled"
      });
      taskCount.inc({
        template,
        user,
        result: "cancelled"
      });
      taskTimer({ result: "cancelled" });
    }
    return {
      skipDryRun,
      markCancelled,
      markSuccessful,
      markFailed
    };
  }
  async function stepStart(task, step) {
    var _a;
    await task.emitLog(`Beginning step ${step.name}`, {
      stepId: step.id,
      status: "processing"
    });
    const template = ((_a = task.spec.templateInfo) == null ? void 0 : _a.entityRef) || "";
    const stepTimer = stepDuration.startTimer({
      template,
      step: step.name
    });
    async function markSuccessful() {
      await task.emitLog(`Finished step ${step.name}`, {
        stepId: step.id,
        status: "completed"
      });
      stepCount.inc({
        template,
        step: step.name,
        result: "ok"
      });
      stepTimer({ result: "ok" });
    }
    async function markCancelled() {
      stepCount.inc({
        template,
        step: step.name,
        result: "cancelled"
      });
      stepTimer({ result: "cancelled" });
    }
    async function markFailed() {
      stepCount.inc({
        template,
        step: step.name,
        result: "failed"
      });
      stepTimer({ result: "failed" });
    }
    async function skipFalsy() {
      await task.emitLog(
        `Skipping step ${step.id} because its if condition was false`,
        { stepId: step.id, status: "skipped" }
      );
      stepTimer({ result: "skipped" });
    }
    return {
      markCancelled,
      markFailed,
      markSuccessful,
      skipFalsy
    };
  }
  return {
    taskStart,
    stepStart
  };
}

class TaskWorker {
  constructor(options) {
    this.options = options;
    this.taskQueue = new PQueue__default["default"]({
      concurrency: options.concurrentTasksLimit
    });
  }
  static async create(options) {
    const {
      taskBroker,
      logger,
      actionRegistry,
      integrations,
      workingDirectory,
      additionalTemplateFilters,
      concurrentTasksLimit = 10,
      // from 1 to Infinity
      additionalTemplateGlobals,
      permissions
    } = options;
    const workflowRunner = new NunjucksWorkflowRunner({
      actionRegistry,
      integrations,
      logger,
      workingDirectory,
      additionalTemplateFilters,
      additionalTemplateGlobals,
      permissions
    });
    return new TaskWorker({
      taskBroker,
      runners: { workflowRunner },
      concurrentTasksLimit,
      permissions
    });
  }
  start() {
    (async () => {
      for (; ; ) {
        await this.onReadyToClaimTask();
        const task = await this.options.taskBroker.claim();
        this.taskQueue.add(() => this.runOneTask(task));
      }
    })();
  }
  onReadyToClaimTask() {
    if (this.taskQueue.pending < this.options.concurrentTasksLimit) {
      return Promise.resolve();
    }
    return new Promise((resolve) => {
      this.taskQueue.once("next", () => {
        resolve();
      });
    });
  }
  async runOneTask(task) {
    try {
      if (task.spec.apiVersion !== "scaffolder.backstage.io/v1beta3") {
        throw new Error(
          `Unsupported Template apiVersion ${task.spec.apiVersion}`
        );
      }
      const { output } = await this.options.runners.workflowRunner.execute(
        task
      );
      await task.complete("completed", { output });
    } catch (error) {
      errors.assertError(error);
      await task.complete("failed", {
        error: { name: error.name, message: error.message }
      });
    }
  }
}

class DecoratedActionsRegistry extends TemplateActionRegistry {
  constructor(innerRegistry, extraActions) {
    super();
    this.innerRegistry = innerRegistry;
    for (const action of extraActions) {
      this.register(action);
    }
  }
  get(actionId) {
    try {
      return super.get(actionId);
    } catch {
      return this.innerRegistry.get(actionId);
    }
  }
}

function createDryRunner(options) {
  return async function dryRun(input) {
    let contentPromise;
    const workflowRunner = new NunjucksWorkflowRunner({
      ...options,
      actionRegistry: new DecoratedActionsRegistry(options.actionRegistry, [
        pluginScaffolderNode.createTemplateAction({
          id: "dry-run:extract",
          supportsDryRun: true,
          async handler(ctx) {
            contentPromise = serializeDirectoryContents(ctx.workspacePath);
            await contentPromise.catch(() => {
            });
          }
        })
      ])
    });
    const dryRunId = uuid.v4();
    const log = new Array();
    const contentsPath = backendCommon.resolveSafeChildPath(
      options.workingDirectory,
      `dry-run-content-${dryRunId}`
    );
    try {
      await deserializeDirectoryContents(contentsPath, input.directoryContents);
      const abortSignal = new AbortController().signal;
      const result = await workflowRunner.execute({
        spec: {
          ...input.spec,
          steps: [
            ...input.spec.steps,
            {
              id: dryRunId,
              name: "dry-run:extract",
              action: "dry-run:extract"
            }
          ],
          templateInfo: {
            entityRef: "template:default/dry-run",
            baseUrl: url.pathToFileURL(
              backendCommon.resolveSafeChildPath(contentsPath, "template.yaml")
            ).toString()
          }
        },
        secrets: input.secrets,
        // No need to update this at the end of the run, so just hard-code it
        done: false,
        isDryRun: true,
        getWorkspaceName: async () => `dry-run-${dryRunId}`,
        cancelSignal: abortSignal,
        async emitLog(message, logMetadata) {
          if ((logMetadata == null ? void 0 : logMetadata.stepId) === dryRunId) {
            return;
          }
          log.push({
            body: {
              ...logMetadata,
              message
            }
          });
        },
        complete: async () => {
          throw new Error("Not implemented");
        }
      });
      if (!contentPromise) {
        throw new Error("Content extraction step was skipped");
      }
      const directoryContents = await contentPromise;
      return {
        log,
        directoryContents,
        output: result.output
      };
    } finally {
      await fs__default["default"].remove(contentsPath);
    }
  };
}

async function getWorkingDirectory(config, logger) {
  if (!config.has("backend.workingDirectory")) {
    return os__default["default"].tmpdir();
  }
  const workingDirectory = config.getString("backend.workingDirectory");
  try {
    await fs__default["default"].access(workingDirectory, fs__default["default"].constants.F_OK | fs__default["default"].constants.W_OK);
    logger.info(`using working directory: ${workingDirectory}`);
  } catch (err) {
    errors.assertError(err);
    logger.error(
      `working directory ${workingDirectory} ${err.code === "ENOENT" ? "does not exist" : "is not writable"}`
    );
    throw err;
  }
  return workingDirectory;
}
function getEntityBaseUrl(entity) {
  var _a, _b;
  let location = (_a = entity.metadata.annotations) == null ? void 0 : _a[catalogModel.ANNOTATION_SOURCE_LOCATION];
  if (!location) {
    location = (_b = entity.metadata.annotations) == null ? void 0 : _b[catalogModel.ANNOTATION_LOCATION];
  }
  if (!location) {
    return void 0;
  }
  const { type, target } = catalogModel.parseLocationRef(location);
  if (type === "url") {
    return target;
  } else if (type === "file") {
    return `file://${target}`;
  }
  return void 0;
}
async function findTemplate(options) {
  const { entityRef, token, catalogApi } = options;
  if (entityRef.kind.toLocaleLowerCase("en-US") !== "template") {
    throw new errors.InputError(`Invalid kind, only 'Template' kind is supported`);
  }
  const template = await catalogApi.getEntityByRef(entityRef, { token });
  if (!template) {
    throw new errors.NotFoundError(
      `Template ${catalogModel.stringifyEntityRef(entityRef)} not found`
    );
  }
  return template;
}

function isTemplatePermissionRuleInput(permissionRule) {
  return permissionRule.resourceType === alpha.RESOURCE_TYPE_SCAFFOLDER_TEMPLATE;
}
function isActionPermissionRuleInput(permissionRule) {
  return permissionRule.resourceType === alpha.RESOURCE_TYPE_SCAFFOLDER_ACTION;
}
function isSupportedTemplate(entity) {
  return entity.apiVersion === "scaffolder.backstage.io/v1beta3";
}
function buildDefaultIdentityClient(options) {
  return {
    getIdentity: async ({ request }) => {
      var _a;
      const header = request.headers.authorization;
      const { logger } = options;
      if (!header) {
        return void 0;
      }
      try {
        const token = (_a = header.match(/^Bearer\s(\S+\.\S+\.\S+)$/i)) == null ? void 0 : _a[1];
        if (!token) {
          throw new TypeError("Expected Bearer with JWT");
        }
        const [_header, rawPayload, _signature] = token.split(".");
        const payload = JSON.parse(
          Buffer.from(rawPayload, "base64").toString()
        );
        if (typeof payload !== "object" || payload === null || Array.isArray(payload)) {
          throw new TypeError("Malformed JWT payload");
        }
        const sub = payload.sub;
        if (typeof sub !== "string") {
          throw new TypeError("Expected string sub claim");
        }
        if (sub === "backstage-server") {
          return void 0;
        }
        catalogModel.parseEntityRef(sub);
        return {
          identity: {
            userEntityRef: sub,
            ownershipEntityRefs: [],
            type: "user"
          },
          token
        };
      } catch (e) {
        logger.error(`Invalid authorization header: ${errors.stringifyError(e)}`);
        return void 0;
      }
    }
  };
}
async function createRouter(options) {
  const router = Router__default["default"]();
  router.use(express__default["default"].json({ limit: "10MB" }));
  const {
    logger: parentLogger,
    config,
    reader,
    database,
    catalogClient,
    actions,
    taskWorkers,
    concurrentTasksLimit,
    scheduler,
    additionalTemplateFilters,
    additionalTemplateGlobals,
    permissions,
    permissionRules
  } = options;
  const logger = parentLogger.child({ plugin: "scaffolder" });
  const identity = options.identity || buildDefaultIdentityClient(options);
  const workingDirectory = await getWorkingDirectory(config, logger);
  const integrations = integration.ScmIntegrations.fromConfig(config);
  let taskBroker;
  if (!options.taskBroker) {
    const databaseTaskStore = await DatabaseTaskStore.create({ database });
    taskBroker = new StorageTaskBroker(databaseTaskStore, logger);
    if (scheduler && databaseTaskStore.listStaleTasks) {
      await scheduler.scheduleTask({
        id: "close_stale_tasks",
        frequency: { cron: "*/5 * * * *" },
        // every 5 minutes, also supports Duration
        timeout: { minutes: 15 },
        fn: async () => {
          const { tasks } = await databaseTaskStore.listStaleTasks({
            timeoutS: 86400
          });
          for (const task of tasks) {
            await databaseTaskStore.shutdownTask(task);
            logger.info(`Successfully closed stale task ${task.taskId}`);
          }
        }
      });
    }
  } else {
    taskBroker = options.taskBroker;
  }
  const actionRegistry = new TemplateActionRegistry();
  const workers = [];
  for (let i = 0; i < (taskWorkers || 1); i++) {
    const worker = await TaskWorker.create({
      taskBroker,
      actionRegistry,
      integrations,
      logger,
      workingDirectory,
      additionalTemplateFilters,
      additionalTemplateGlobals,
      concurrentTasksLimit,
      permissions
    });
    workers.push(worker);
  }
  const actionsToRegister = Array.isArray(actions) ? actions : createBuiltinActions({
    integrations,
    catalogClient,
    reader,
    config,
    additionalTemplateFilters,
    additionalTemplateGlobals
  });
  actionsToRegister.forEach((action) => actionRegistry.register(action));
  workers.forEach((worker) => worker.start());
  const dryRunner = createDryRunner({
    actionRegistry,
    integrations,
    logger,
    workingDirectory,
    additionalTemplateFilters,
    additionalTemplateGlobals,
    permissions
  });
  const templateRules = Object.values(
    scaffolderTemplateRules
  );
  const actionRules = Object.values(
    scaffolderActionRules
  );
  if (permissionRules) {
    templateRules.push(
      ...permissionRules.filter(isTemplatePermissionRuleInput)
    );
    actionRules.push(...permissionRules.filter(isActionPermissionRuleInput));
  }
  const isAuthorized = pluginPermissionNode.createConditionAuthorizer(Object.values(templateRules));
  const permissionIntegrationRouter = pluginPermissionNode.createPermissionIntegrationRouter({
    resources: [
      {
        resourceType: alpha.RESOURCE_TYPE_SCAFFOLDER_TEMPLATE,
        permissions: alpha.scaffolderTemplatePermissions,
        rules: templateRules
      },
      {
        resourceType: alpha.RESOURCE_TYPE_SCAFFOLDER_ACTION,
        permissions: alpha.scaffolderActionPermissions,
        rules: actionRules
      }
    ]
  });
  router.use(permissionIntegrationRouter);
  router.get(
    "/v2/templates/:namespace/:kind/:name/parameter-schema",
    async (req, res) => {
      var _a, _b;
      const userIdentity = await identity.getIdentity({
        request: req
      });
      const token = userIdentity == null ? void 0 : userIdentity.token;
      const template = await authorizeTemplate(req.params, token);
      const parameters = [(_a = template.spec.parameters) != null ? _a : []].flat();
      res.json({
        title: (_b = template.metadata.title) != null ? _b : template.metadata.name,
        description: template.metadata.description,
        "ui:options": template.metadata["ui:options"],
        steps: parameters.map((schema) => {
          var _a2;
          return {
            title: (_a2 = schema.title) != null ? _a2 : "Please enter the following information",
            description: schema.description,
            schema
          };
        })
      });
    }
  ).get("/v2/actions", async (_req, res) => {
    const actionsList = actionRegistry.list().map((action) => {
      return {
        id: action.id,
        description: action.description,
        examples: action.examples,
        schema: action.schema
      };
    });
    res.json(actionsList);
  }).post("/v2/tasks", async (req, res) => {
    var _a, _b;
    const templateRef = req.body.templateRef;
    const { kind, namespace, name } = catalogModel.parseEntityRef(templateRef, {
      defaultKind: "template"
    });
    const callerIdentity = await identity.getIdentity({
      request: req
    });
    const token = callerIdentity == null ? void 0 : callerIdentity.token;
    const userEntityRef = callerIdentity == null ? void 0 : callerIdentity.identity.userEntityRef;
    const userEntity = userEntityRef ? await catalogClient.getEntityByRef(userEntityRef, { token }) : void 0;
    let auditLog = `Scaffolding task for ${templateRef}`;
    if (userEntityRef) {
      auditLog += ` created by ${userEntityRef}`;
    }
    logger.info(auditLog);
    const values = req.body.values;
    const template = await authorizeTemplate(
      { kind, namespace, name },
      token
    );
    for (const parameters of [(_a = template.spec.parameters) != null ? _a : []].flat()) {
      const result2 = jsonschema.validate(values, parameters);
      if (!result2.valid) {
        res.status(400).json({ errors: result2.errors });
        return;
      }
    }
    const baseUrl = getEntityBaseUrl(template);
    const taskSpec = {
      apiVersion: template.apiVersion,
      steps: template.spec.steps.map((step, index) => {
        var _a2, _b2;
        return {
          ...step,
          id: (_a2 = step.id) != null ? _a2 : `step-${index + 1}`,
          name: (_b2 = step.name) != null ? _b2 : step.action
        };
      }),
      output: (_b = template.spec.output) != null ? _b : {},
      parameters: values,
      user: {
        entity: userEntity,
        ref: userEntityRef
      },
      templateInfo: {
        entityRef: catalogModel.stringifyEntityRef({ kind, name, namespace }),
        baseUrl,
        entity: {
          metadata: template.metadata
        }
      }
    };
    const result = await taskBroker.dispatch({
      spec: taskSpec,
      createdBy: userEntityRef,
      secrets: {
        ...req.body.secrets,
        backstageToken: token
      }
    });
    res.status(201).json({ id: result.taskId });
  }).get("/v2/tasks", async (req, res) => {
    const [userEntityRef] = [req.query.createdBy].flat();
    if (typeof userEntityRef !== "string" && typeof userEntityRef !== "undefined") {
      throw new errors.InputError("createdBy query parameter must be a string");
    }
    if (!taskBroker.list) {
      throw new Error(
        "TaskBroker does not support listing tasks, please implement the list method on the TaskBroker."
      );
    }
    const tasks = await taskBroker.list({
      createdBy: userEntityRef
    });
    res.status(200).json(tasks);
  }).get("/v2/tasks/:taskId", async (req, res) => {
    const { taskId } = req.params;
    const task = await taskBroker.get(taskId);
    if (!task) {
      throw new errors.NotFoundError(`Task with id ${taskId} does not exist`);
    }
    delete task.secrets;
    res.status(200).json(task);
  }).post("/v2/tasks/:taskId/cancel", async (req, res) => {
    var _a;
    const { taskId } = req.params;
    await ((_a = taskBroker.cancel) == null ? void 0 : _a.call(taskBroker, taskId));
    res.status(200).json({ status: "cancelled" });
  }).get("/v2/tasks/:taskId/eventstream", async (req, res) => {
    const { taskId } = req.params;
    const after = req.query.after !== void 0 ? Number(req.query.after) : void 0;
    logger.debug(`Event stream observing taskId '${taskId}' opened`);
    res.writeHead(200, {
      Connection: "keep-alive",
      "Cache-Control": "no-cache",
      "Content-Type": "text/event-stream"
    });
    const subscription = taskBroker.event$({ taskId, after }).subscribe({
      error: (error) => {
        logger.error(
          `Received error from event stream when observing taskId '${taskId}', ${error}`
        );
        res.end();
      },
      next: ({ events }) => {
        var _a;
        let shouldUnsubscribe = false;
        for (const event of events) {
          res.write(
            `event: ${event.type}
data: ${JSON.stringify(event)}

`
          );
          if (event.type === "completion") {
            shouldUnsubscribe = true;
          }
        }
        (_a = res.flush) == null ? void 0 : _a.call(res);
        if (shouldUnsubscribe) {
          subscription.unsubscribe();
          res.end();
        }
      }
    });
    req.on("close", () => {
      subscription.unsubscribe();
      logger.debug(`Event stream observing taskId '${taskId}' closed`);
    });
  }).get("/v2/tasks/:taskId/events", async (req, res) => {
    const { taskId } = req.params;
    const after = Number(req.query.after) || void 0;
    const timeout = setTimeout(() => {
      res.json([]);
    }, 3e4);
    const subscription = taskBroker.event$({ taskId, after }).subscribe({
      error: (error) => {
        logger.error(
          `Received error from event stream when observing taskId '${taskId}', ${error}`
        );
      },
      next: ({ events }) => {
        clearTimeout(timeout);
        subscription.unsubscribe();
        res.json(events);
      }
    });
    req.on("close", () => {
      subscription.unsubscribe();
      clearTimeout(timeout);
    });
  }).post("/v2/dry-run", async (req, res) => {
    var _a, _b, _c, _d;
    const bodySchema = zod.z.object({
      template: zod.z.unknown(),
      values: zod.z.record(zod.z.unknown()),
      secrets: zod.z.record(zod.z.string()).optional(),
      directoryContents: zod.z.array(
        zod.z.object({ path: zod.z.string(), base64Content: zod.z.string() })
      )
    });
    const body = await bodySchema.parseAsync(req.body).catch((e) => {
      throw new errors.InputError(`Malformed request: ${e}`);
    });
    const template = body.template;
    if (!await pluginScaffolderCommon.templateEntityV1beta3Validator.check(template)) {
      throw new errors.InputError("Input template is not a template");
    }
    const token = (_a = await identity.getIdentity({
      request: req
    })) == null ? void 0 : _a.token;
    for (const parameters of [(_b = template.spec.parameters) != null ? _b : []].flat()) {
      const result2 = jsonschema.validate(body.values, parameters);
      if (!result2.valid) {
        res.status(400).json({ errors: result2.errors });
        return;
      }
    }
    const steps = template.spec.steps.map((step, index) => {
      var _a2, _b2;
      return {
        ...step,
        id: (_a2 = step.id) != null ? _a2 : `step-${index + 1}`,
        name: (_b2 = step.name) != null ? _b2 : step.action
      };
    });
    const result = await dryRunner({
      spec: {
        apiVersion: template.apiVersion,
        steps,
        output: (_c = template.spec.output) != null ? _c : {},
        parameters: body.values
      },
      directoryContents: ((_d = body.directoryContents) != null ? _d : []).map((file) => ({
        path: file.path,
        content: Buffer.from(file.base64Content, "base64")
      })),
      secrets: {
        ...body.secrets,
        ...token && { backstageToken: token }
      }
    });
    res.status(200).json({
      ...result,
      steps,
      directoryContents: result.directoryContents.map((file) => ({
        path: file.path,
        executable: file.executable,
        base64Content: file.content.toString("base64")
      }))
    });
  });
  const app = express__default["default"]();
  app.set("logger", logger);
  app.use("/", router);
  async function authorizeTemplate(entityRef, token) {
    const template = await findTemplate({
      catalogApi: catalogClient,
      entityRef,
      token
    });
    if (!isSupportedTemplate(template)) {
      throw new errors.InputError(
        `Unsupported apiVersion field in schema entity, ${template.apiVersion}`
      );
    }
    if (!permissions) {
      return template;
    }
    const [parameterDecision, stepDecision] = await permissions.authorizeConditional(
      [
        { permission: alpha.templateParameterReadPermission },
        { permission: alpha.templateStepReadPermission }
      ],
      { token }
    );
    if (Array.isArray(template.spec.parameters)) {
      template.spec.parameters = template.spec.parameters.filter(
        (step) => isAuthorized(parameterDecision, step)
      );
    } else if (template.spec.parameters && !isAuthorized(parameterDecision, template.spec.parameters)) {
      template.spec.parameters = void 0;
    }
    template.spec.steps = template.spec.steps.filter(
      (step) => isAuthorized(stepDecision, step)
    );
    return template;
  }
  return app;
}

class ScaffolderEntitiesProcessor {
  constructor() {
    this.validators = [pluginScaffolderCommon.templateEntityV1beta3Validator];
  }
  getProcessorName() {
    return "ScaffolderEntitiesProcessor";
  }
  async validateEntityKind(entity) {
    for (const validator of this.validators) {
      if (await validator.check(entity)) {
        return true;
      }
    }
    return false;
  }
  async postProcessEntity(entity, _location, emit) {
    const selfRef = catalogModel.getCompoundEntityRef(entity);
    if (entity.apiVersion === "scaffolder.backstage.io/v1beta3" && entity.kind === "Template") {
      const template = entity;
      const target = template.spec.owner;
      if (target) {
        const targetRef = catalogModel.parseEntityRef(target, {
          defaultKind: "Group",
          defaultNamespace: selfRef.namespace
        });
        emit(
          pluginCatalogNode.processingResult.relation({
            source: selfRef,
            type: catalogModel.RELATION_OWNED_BY,
            target: {
              kind: targetRef.kind,
              namespace: targetRef.namespace,
              name: targetRef.name
            }
          })
        );
        emit(
          pluginCatalogNode.processingResult.relation({
            source: {
              kind: targetRef.kind,
              namespace: targetRef.namespace,
              name: targetRef.name
            },
            type: catalogModel.RELATION_OWNER_OF,
            target: selfRef
          })
        );
      }
    }
    return entity;
  }
}

exports.DatabaseTaskStore = DatabaseTaskStore;
exports.ScaffolderEntitiesProcessor = ScaffolderEntitiesProcessor;
exports.TaskManager = TaskManager;
exports.TaskWorker = TaskWorker;
exports.TemplateActionRegistry = TemplateActionRegistry;
exports.createBuiltinActions = createBuiltinActions;
exports.createCatalogRegisterAction = createCatalogRegisterAction;
exports.createCatalogWriteAction = createCatalogWriteAction;
exports.createDebugLogAction = createDebugLogAction;
exports.createFetchCatalogEntityAction = createFetchCatalogEntityAction;
exports.createFetchPlainAction = createFetchPlainAction;
exports.createFetchPlainFileAction = createFetchPlainFileAction;
exports.createFetchTemplateAction = createFetchTemplateAction;
exports.createFilesystemDeleteAction = createFilesystemDeleteAction;
exports.createFilesystemRenameAction = createFilesystemRenameAction;
exports.createGithubActionsDispatchAction = createGithubActionsDispatchAction;
exports.createGithubIssuesLabelAction = createGithubIssuesLabelAction;
exports.createGithubRepoCreateAction = createGithubRepoCreateAction;
exports.createGithubRepoPushAction = createGithubRepoPushAction;
exports.createGithubWebhookAction = createGithubWebhookAction;
exports.createPublishAzureAction = createPublishAzureAction;
exports.createPublishBitbucketAction = createPublishBitbucketAction;
exports.createPublishBitbucketCloudAction = createPublishBitbucketCloudAction;
exports.createPublishBitbucketServerAction = createPublishBitbucketServerAction;
exports.createPublishGerritAction = createPublishGerritAction;
exports.createPublishGerritReviewAction = createPublishGerritReviewAction;
exports.createPublishGithubAction = createPublishGithubAction;
exports.createPublishGithubPullRequestAction = createPublishGithubPullRequestAction;
exports.createPublishGitlabAction = createPublishGitlabAction;
exports.createPublishGitlabMergeRequestAction = createPublishGitlabMergeRequestAction;
exports.createRouter = createRouter;
exports.createWaitAction = createWaitAction;
exports.executeShellCommand = executeShellCommand;
exports.fetchContents = fetchContents;
exports.scaffolderActionRules = scaffolderActionRules;
exports.scaffolderTemplateRules = scaffolderTemplateRules;
//# sourceMappingURL=ScaffolderEntitiesProcessor-021c5dcb.cjs.js.map
